{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n",
      "unq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples: 100%|██████████| 12/12 [00:00<00:00, 30.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import functools\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import importlib as imp\n",
    "\n",
    "from tqdm import tqdm\n",
    "tprint = tqdm.write\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.pool import radius_graph\n",
    "from torch_geometric.transforms import FixedPoints\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "\n",
    "# from torch_geometric.nn.conv import PointNetConv\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    PairOptTensor,\n",
    "    PairTensor\n",
    ")\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "\n",
    "import aegnn\n",
    "# from aegnn.models.networks.my_fuse import MyConvBNReLU\n",
    "\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "torch.set_printoptions(precision=6)\n",
    "\n",
    "# path = \"/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230328183028/epoch=0-step=202.pt\" #fuse\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230331161858/epoch=18-step=3856.pt' # fuse, quant test\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230331160055/epoch=12-step=2638.pt' # fuse, pos div 32\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230331164223/epoch=11-step=2435.pt' # fuse, pos abs\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230331230610/epoch=99-step=20299.pt' # quant test\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230331220429/epoch=1-step=405.pt' # quant debug: dpos = 0\n",
    "# path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230405180647/epoch=21-step=4465.pt' # quant debug\n",
    "path = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20230406013526/epoch=0-step=202.pt' # quant debug 2\n",
    "model = torch.load(path).to(device)\n",
    "model.eval()\n",
    "dm = aegnn.datasets.NCars(batch_size=1, shuffle=False)\n",
    "dm.setup()\n",
    "# print(model.model.fuse1.local_nn.weight)\n",
    "# data_loader = dm.val_dataloader(num_workers=1).__iter__()\n",
    "data_loader = dm.val_dataloader(num_workers=1)\n",
    "\n",
    "assert model.model.fuse1.local_nn.bias is None\n",
    "\n",
    "if isinstance(model, pl.LightningModule):\n",
    "    nn_model = model._modules['model']\n",
    "    nn_layers = nn_model._modules\n",
    "elif isinstance(model, torch.nn.Module):\n",
    "    nn_layers = model._modules\n",
    "else:\n",
    "    raise TypeError(f'The type of model is {type(model)}, not a `torch.nn.Module` or a `pl.LightningModule`')\n",
    "\n",
    "from copy import deepcopy\n",
    "unfused_model = deepcopy(model.model)\n",
    "unfused_model = unfused_model.to(model.device)\n",
    "unfused_model.eval()\n",
    "\n",
    "# for key, nn in nn_layers.items():\n",
    "#     if isinstance(nn, aegnn.models.networks.my_fuse.MyConvBNReLU):\n",
    "#         # nn_layers[key].module.running_mean = torch.zeros_like(nn_layers[key].module.running_mean)\n",
    "#         # nn_layers[key].module.running_var = torch.ones_like(nn_layers[key].module.running_var)\n",
    "#         # nn_layers[key].module.bias = torch.nn.Parameter(torch.zeros_like(nn_layers[key].module.bias))\n",
    "#         # nn_layers[key].module.weight = torch.nn.Parameter(torch.ones_like(nn_layers[key].module.weight))\n",
    "#         # nn_layers[key].module.eps = 1e-16\n",
    "#         nn_layers[key].to_fused()\n",
    "#         pass\n",
    "# fused_model = model\n",
    "# fused_model.eval()\n",
    "assert model.model.fused is False\n",
    "assert model.model.quantized is False\n",
    "model.model.to_fused()\n",
    "assert model.model.fused is True\n",
    "assert model.model.quantized is False\n",
    "\n",
    "model.model.debug_logger()\n",
    "\n",
    "fused_model = model\n",
    "fused_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "num_test_samples = 12\n",
    "# num_test_samples = 2460\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(tqdm(data_loader, position=1, desc='Samples', total=num_test_samples)):\n",
    "        torch.cuda.empty_cache()\n",
    "        if i==num_test_samples: break\n",
    "        # tprint(f\"\\nSample {i}, file_id {sample.file_id}:\")\n",
    "\n",
    "        sample = sample.to(model.device)\n",
    "        tot_nodes = sample.num_nodes\n",
    "\n",
    "\n",
    "        unfused_test_sample = sample.clone().detach()\n",
    "        output_unfused = unfused_model.forward(unfused_test_sample)\n",
    "        y_unfused = torch.argmax(output_unfused, dim=-1)\n",
    "        # tprint(f'unfused output = {output_unfused}')\n",
    "        # tprint(f'{unfused_model.fuse1.local_nn.weight}')\n",
    "\n",
    "        fused_test_sample = sample.clone().detach()\n",
    "        output_fused = fused_model.forward(fused_test_sample)\n",
    "        y_fused = torch.argmax(output_fused, dim=-1)\n",
    "        # tprint(f'  fused output = {output_fused}')\n",
    "        # tprint(f'{fused_model.model.fuse1.local_nn.weight}')\n",
    "        # tprint(fused_model.model.fuse1.fused)\n",
    "\n",
    "        diff = torch.allclose(y_unfused, y_fused)\n",
    "        if diff is not True:\n",
    "            print(i)\n",
    "            print(f'unfused output = {output_unfused}')\n",
    "            print(f'  fused output = {output_fused}')\n",
    "        # print(diff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot x max = 1.0\n",
      "tot y max = 1.0153450965881348\n",
      "tot wx   abs max = 2.716198682785034\n",
      "tot wpos abs max = 3.9919888973236084\n",
      "calibre = True\n",
      "\n",
      "tot x max = 1.0153450965881348\n",
      "tot y max = 2.8550615310668945\n",
      "tot wx   abs max = 3.148315668106079\n",
      "tot wpos abs max = 1.8805090188980103\n",
      "calibre = True\n",
      "\n",
      "tot x max = 2.8550615310668945\n",
      "tot y max = 5.430680751800537\n",
      "tot wx   abs max = 1.149037480354309\n",
      "tot wpos abs max = 0.9192111492156982\n",
      "calibre = True\n",
      "\n",
      "tot x max = 5.430680751800537\n",
      "tot y max = 5.118592262268066\n",
      "tot wx   abs max = 1.0311261415481567\n",
      "tot wpos abs max = 0.7703390717506409\n",
      "calibre = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aegnn.models.networks.my_fuse import MyConvBNReLU\n",
    "\n",
    "for block in fused_model.model.children():\n",
    "    if isinstance(block,MyConvBNReLU):\n",
    "\n",
    "        # print(f'x max = {block.obs_x.max_val}')\n",
    "        # print(f'x min = {block.obs_x.min_val}')\n",
    "        # x_scale, _ = block.obs_x.calculate_qparams()\n",
    "        # print(f'x scale = \\n{x_scale}')\n",
    "        tot_x_max = torch.max(block.obs_x.max_val)\n",
    "        print(f'tot x max = {tot_x_max}')\n",
    "\n",
    "        # print(f'y max = {block.obs_y.max_val}')\n",
    "        tot_y_max = torch.max(block.obs_y.max_val)\n",
    "        print(f'tot y max = {tot_y_max}')\n",
    "\n",
    "        # print(f'w max = {block.obs_w.max_val}')\n",
    "        # print(f'w min = {block.obs_w.min_val}')\n",
    "        # # # w_scale, _ = block.obs_w.calculate_qparams()\n",
    "        # # # print(f'w scale = \\n{w_scale}')\n",
    "        # tot_w_max = torch.max(block.obs_w.max_val)\n",
    "        # tot_w_min = torch.min(block.obs_w.min_val)\n",
    "        # print(f'tot w max = {tot_w_max}')\n",
    "        # print(f'tot w min = {tot_w_min}')\n",
    "        tot_wx_max = torch.max(block.obs_w.max_val[:-2])\n",
    "        tot_wpos_max = torch.max(block.obs_w.max_val[-2:])\n",
    "        tot_wx_min = torch.min(block.obs_w.min_val[:-2])\n",
    "        tot_wpos_min = torch.min(block.obs_w.min_val[-2:])\n",
    "        # print(f'tot wx   max = {tot_wx_max}, min = {tot_wx_min}')\n",
    "        # print(f'tot wpos max = {tot_wpos_max}, min = {tot_wpos_min}')\n",
    "        tot_wx_abs_max = torch.maximum(torch.abs(tot_wx_max), torch.abs(tot_wx_min))\n",
    "        tot_wpos_abs_max = torch.maximum(torch.abs(tot_wpos_max), torch.abs(tot_wpos_min))\n",
    "        print(f'tot wx   abs max = {tot_wx_abs_max}')\n",
    "        print(f'tot wpos abs max = {tot_wpos_abs_max}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # tot_b_max = torch.max(block.obs_b.max_val)\n",
    "        # tot_b_min = torch.min(block.obs_b.min_val)\n",
    "        # print(f'tot b max = {tot_b_max}')\n",
    "        # print(f'tot b min = {tot_b_min}')\n",
    "        \n",
    "        print(f'calibre = {block.calibre}')\n",
    "        # print(f'x_scale = {block.x_scale}')\n",
    "        # print(f'y_scale = {block.y_scale}')\n",
    "        # print(f'w_scale = {block.w_scale}')\n",
    "        # print(f'b_scale = {block.b_scale}')\n",
    "        # print(f'M = {block.M}')\n",
    "        \n",
    "        print('')\n",
    "\n",
    "        # print(f'w min = {block.local_nn.weight}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphRes(\n",
       "  (fuse1): MyConvBNReLU(1, 16)\n",
       "  (fuse2): MyConvBNReLU(16, 32)\n",
       "  (fuse3): MyConvBNReLU(32, 32)\n",
       "  (fuse4): MyConvBNReLU(32, 32)\n",
       "  (pool): MaxPoolingX(voxel_size=tensor([15.000000, 12.500000], device='cuda:0'), size=64)\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert fused_model.model.quantized is False\n",
    "fused_model.model.quant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fused_model.model.quantized is True\n",
    "assert fused_model.model.fuse1.quantized is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized = True\n",
      "x_scale = 0.011764707043766975\n",
      "y_scale = 0.011764707043766975\n",
      "w_scale = 0.03143298253417015\n",
      "dpos_scale = 0.0117647061124444\n",
      "b_scale = 0.0003697998181451112\n",
      "M = 0.03143298253417015\n",
      "m = 32960.0\n",
      "M<<>> = 0.03143310546875\n",
      "\n",
      "quantized = True\n",
      "x_scale = 0.011764707043766975\n",
      "y_scale = 0.011764707043766975\n",
      "w_scale = 0.02478988654911518\n",
      "dpos_scale = 0.0117647061124444\n",
      "b_scale = 0.00029164575971663\n",
      "M = 0.02478988654911518\n",
      "m = 25994.0\n",
      "M<<>> = 0.024789810180664062\n",
      "\n",
      "quantized = True\n",
      "x_scale = 0.011764707043766975\n",
      "y_scale = 0.02129678800702095\n",
      "w_scale = 0.009047538973391056\n",
      "dpos_scale = 0.0117647061124444\n",
      "b_scale = 0.00010644164285622537\n",
      "M = 0.0049980138428509235\n",
      "m = 5241.0\n",
      "M<<>> = 0.004998207092285156\n",
      "\n",
      "quantized = True\n",
      "x_scale = 0.02129678800702095\n",
      "y_scale = 0.02007291279733181\n",
      "w_scale = 0.008119103498756886\n",
      "dpos_scale = 0.021276595070958138\n",
      "b_scale = 0.0001729108189465478\n",
      "M = 0.008614136837422848\n",
      "m = 9033.0\n",
      "M<<>> = 0.008614540100097656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for block in fused_model.model.children():\n",
    "    if isinstance(block,MyConvBNReLU):\n",
    "        \n",
    "        print(f'quantized = {block.quantized}')\n",
    "        print(f'x_scale = {block.x_scale}')\n",
    "        print(f'y_scale = {block.y_scale}')\n",
    "        print(f'w_scale = {block.w_scale}')\n",
    "        print(f'dpos_scale = {block.dpos_scale}')\n",
    "        # print(f'1/dpos_scale = {1/block.dpos_scale}')\n",
    "        # print(f'1/round(1/dpos_scale) = {(1/torch.round(1/block.dpos_scale))}')\n",
    "        # print(f'wx_scale = {block.wx_scale}')\n",
    "        # print(f'wpos_scale = {block.wpos_scale}')\n",
    "        print(f'b_scale = {block.b_scale}')\n",
    "        print(f'M = {block.M}')\n",
    "        m = torch.round(block.M * 2**(20))\n",
    "        print(f'm = {m}')\n",
    "        print(f'M<<>> = {2**(-20)*m}')\n",
    "\n",
    "        # print(f'b_new = {block.b_new}')\n",
    "        # print(f'b_quant = {block.b_quant}')\n",
    "\n",
    "        # print(f'w_quant = {block.w_quant}')\n",
    "        \n",
    "        print('')\n",
    "\n",
    "        # print(f'w min = {block.local_nn.weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fuse1': tensor([[0.776611, 0.872222, 0.673569,  ..., 0.812895, 0.958127, 1.015345],\n",
       "         [0.776611, 0.872222, 0.060893,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [0.776611, 0.872222, 0.469343,  ..., 0.000000, 0.958127, 0.000000],\n",
       "         ...,\n",
       "         [0.000000, 0.872222, 0.673569,  ..., 0.000000, 0.000000, 1.015345],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.812895, 0.000000, 0.000000],\n",
       "         [0.000000, 0.000000, 0.469343,  ..., 0.812895, 0.000000, 0.000000]],\n",
       "        device='cuda:0'),\n",
       " 'fuse2': tensor([[0.233412, 0.000000, 1.107550,  ..., 0.000000, 0.000000, 0.845957],\n",
       "         [0.000000, 0.726429, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [0.250394, 0.676641, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         ...,\n",
       "         [0.000000, 0.621077, 0.000000,  ..., 0.000000, 0.000000, 0.420607],\n",
       "         [1.367213, 0.000000, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [0.984320, 0.000000, 0.000000,  ..., 0.000000, 1.647511, 0.006292]],\n",
       "        device='cuda:0'),\n",
       " 'fuse3': tensor([[0.000000, 1.283160, 0.000000,  ..., 0.206154, 0.900959, 0.115247],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 1.183646, 0.000000, 0.630410],\n",
       "         [0.000000, 0.000000, 1.168698,  ..., 1.208848, 0.000000, 0.323153],\n",
       "         ...,\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.000000, 0.000000, 1.278988],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.277006, 0.000000, 0.000000],\n",
       "         [1.310557, 0.000000, 0.101262,  ..., 0.000000, 0.000000, 0.000000]],\n",
       "        device='cuda:0'),\n",
       " 'fuse4': tensor([[0.000000, 0.996635, 0.000000,  ..., 0.000000, 1.791741, 0.159665],\n",
       "         [0.038734, 1.437726, 0.000000,  ..., 0.000000, 1.259855, 0.471200],\n",
       "         [0.000000, 1.231664, 0.000000,  ..., 0.596478, 1.035509, 0.000000],\n",
       "         ...,\n",
       "         [0.425053, 1.162234, 0.000000,  ..., 1.792171, 0.000000, 0.000000],\n",
       "         [0.000000, 0.898020, 1.310060,  ..., 0.358621, 1.151588, 0.000000],\n",
       "         [0.074600, 0.173718, 0.109326,  ..., 0.237032, 0.000000, 0.000000]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.debug_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start quant test\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "q\n",
      "unfused_acc = 0.75\n",
      "quant_acc = 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "quant_model = model\n",
    "print('start quant test')\n",
    "# model.model.debug_logger()\n",
    "# num_test_samples = 2460\n",
    "num_test_samples = 12\n",
    "\n",
    "unfused_correct = 0\n",
    "quant_correct = 0\n",
    "with torch.no_grad():\n",
    "    # for i, sample in enumerate(tqdm(data_loader, position=1, desc='Samples', total=num_test_samples)):\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        if i==num_test_samples: break\n",
    "        # tprint(f\"\\nSample {i}, file_id {sample.file_id}:\")\n",
    "\n",
    "        sample = sample.to(model.device)\n",
    "        tot_nodes = sample.num_nodes\n",
    "\n",
    "\n",
    "        unfused_test_sample = sample.clone().detach()\n",
    "        output_unfused = unfused_model.forward(unfused_test_sample)\n",
    "        y_unfused = torch.argmax(output_unfused, dim=-1)\n",
    "        # print(f'unfused output = {output_unfused}')\n",
    "        # print(f'x = {unfused_test_sample.x}')\n",
    "        # tprint(f'{unfused_model.fuse1.local_nn.weight}')\n",
    "        unfused_hit = torch.allclose(y_unfused, unfused_test_sample.y)\n",
    "        if unfused_hit: unfused_correct += 1\n",
    "\n",
    "        quant_test_sample = sample.clone().detach()\n",
    "        output_quant = quant_model.forward(quant_test_sample)\n",
    "        y_quant = torch.argmax(output_quant, dim=-1)\n",
    "        # print(f'  quant output = {output_quant}')\n",
    "        # print(f'x = {quant_test_sample.x}')\n",
    "        # tprint(f'{quant_model.model.fuse1.local_nn.weight}')\n",
    "        # tprint(quant_model.model.fuse1.fused)\n",
    "\n",
    "        quant_hit = torch.allclose(y_quant, quant_test_sample.y)\n",
    "        if quant_hit: quant_correct += 1\n",
    "\n",
    "        # diff = torch.allclose(y_unfused, y_quant)\n",
    "        # if diff is not True:\n",
    "        #     print(i)\n",
    "        #     print(f'unfused output = {output_unfused}')\n",
    "        #     print(f'  quant output = {output_quant}')\n",
    "        #     # print(unfused_test_sample.x)\n",
    "        #     # print(quant_test_sample.x)\n",
    "        # print(diff)\n",
    "\n",
    "unfused_acc = unfused_correct / num_test_samples\n",
    "quant_acc = quant_correct / num_test_samples\n",
    "\n",
    "print(f'unfused_acc = {unfused_acc}')\n",
    "print(f'quant_acc = {quant_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fuse1': tensor([[0.811765, 0.870588, 0.670588,  ..., 0.823529, 0.964706, 1.011765],\n",
       "         [0.811765, 0.870588, 0.105882,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [0.811765, 0.870588, 0.482353,  ..., 0.000000, 0.964706, 0.000000],\n",
       "         ...,\n",
       "         [0.000000, 0.870588, 0.670588,  ..., 0.000000, 0.000000, 1.011765],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.823529, 0.000000, 0.000000],\n",
       "         [0.000000, 0.000000, 0.482353,  ..., 0.823529, 0.000000, 0.000000]],\n",
       "        device='cuda:0'),\n",
       " 'fuse2': tensor([[0.176471, 0.000000, 1.129412,  ..., 0.000000, 0.000000, 0.811765],\n",
       "         [0.000000, 0.729412, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [0.247059, 0.682353, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         ...,\n",
       "         [0.000000, 0.635294, 0.000000,  ..., 0.000000, 0.000000, 0.423529],\n",
       "         [1.423530, 0.000000, 0.000000,  ..., 0.000000, 0.000000, 0.000000],\n",
       "         [1.035294, 0.000000, 0.000000,  ..., 0.000000, 1.670588, 0.000000]],\n",
       "        device='cuda:0'),\n",
       " 'fuse3': tensor([[0.000000, 1.213917, 0.000000,  ..., 0.191671, 0.915762, 0.021297],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 1.213917, 0.000000, 0.596310],\n",
       "         [0.000000, 0.000000, 1.256510,  ..., 1.277807, 0.000000, 0.234265],\n",
       "         ...,\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.000000, 0.000000, 1.171323],\n",
       "         [0.000000, 0.000000, 0.000000,  ..., 0.298155, 0.000000, 0.000000],\n",
       "         [1.192620, 0.000000, 0.042594,  ..., 0.000000, 0.000000, 0.000000]],\n",
       "        device='cuda:0'),\n",
       " 'fuse4': tensor([[0.000000, 1.104010, 0.000000,  ..., 0.000000, 2.127729, 0.160583],\n",
       "         [0.120437, 1.545614, 0.000000,  ..., 0.000000, 1.284666, 0.281021],\n",
       "         [0.000000, 1.385031, 0.000000,  ..., 0.762771, 1.164229, 0.000000],\n",
       "         ...,\n",
       "         [0.401458, 1.224448, 0.000000,  ..., 1.866781, 0.000000, 0.000000],\n",
       "         [0.000000, 0.883208, 1.284666,  ..., 0.301094, 1.304739, 0.000000],\n",
       "         [0.040146, 0.281021, 0.000000,  ..., 0.381385, 0.000000, 0.000000]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.debug_dqy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in quant_model.model.children():\n",
    "    if isinstance(nn, MyConvBNReLU):\n",
    "        w_quant = nn.local_nn.weight\n",
    "        b_quant = nn.b_quant\n",
    "        print(w_quant)\n",
    "        print(b_quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aegnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
