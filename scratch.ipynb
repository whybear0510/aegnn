{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning.metrics.functional as pl_metrics\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import subgraph\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import elu\n",
    "from torch_geometric.nn.conv import SplineConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 134.74224981457488, avg_Mflop_per_ev = 0.03368556245364372\n",
    "dense: std acc_Mflop_per_ev = 1170.527851753108, std avg_Mflop_per_ev = 0.29263196293827703\n",
    "```\n",
    "\n",
    "For 100 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 3.414027443525552, avg_Mflop_per_ev = 0.034140274435255524\n",
    "dense: std acc_Mflop_per_ev = 28.595094207357473, std avg_Mflop_per_ev = 0.28595094207357474\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected formula for calculating FLOPS (according to updated paper), leading to:\n",
    "\n",
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 240.93893365788432, avg_Mflop_per_ev = 0.06023473341447108\n",
    "dense: std acc_Mflop_per_ev = 2096.876591199398, std avg_Mflop_per_ev = 0.5242191477998495\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = aegnn.datasets.NCars(batch_size=1, shuffle=False)\n",
    "data_module.setup()\n",
    "dm = data_module.train_dataset\n",
    "\n",
    "# cnt = 0\n",
    "# for i, dms in enumerate(dm):\n",
    "#     cnt += 1\n",
    "#     print(i)\n",
    "\n",
    "# print(cnt)\n",
    "\n",
    "# num_trials=100\n",
    "# nodes=[]\n",
    "# nodes_cnt=0\n",
    "# for index in tqdm(range(num_trials)):\n",
    "#     sample = dm[index % len(dm)]\n",
    "#     nodes.append(sample.num_nodes)\n",
    "#     nodes_cnt += sample.num_nodes\n",
    "# print(nodes_cnt)\n",
    "\n",
    "print(dm.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if add async code into train.py\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_epoch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end  \n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'make_model_asynchronous.<locals>.async_forward'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if I use wandb:\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)  \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)   \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_e\n",
    "poch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end\n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'Settings._validator_factory.<locals>.helper'\n",
    "```\n",
    "Problems seem to be at logger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb import sdk as wandb_sdk\n",
    "\n",
    "wandb.init(project=\"aegnn\", entity=\"yyfteam\")\n",
    "# log_settings = wandb.Settings(start_method=\"thread\")\n",
    "log_settings = wandb.Settings(start_method=\"fork\")\n",
    "wandb_sdk.Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "edge_attr = torch_geometric.transforms.Cartesian(cat=False, max_value=10.0)\n",
    "\n",
    "print(type(edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "initial_lr = 0.5\n",
    "\n",
    "\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "net_1 = model()\n",
    "\n",
    "def LRPolicy(epoch):\n",
    "    if epoch < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.1\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(net_1.parameters(), lr = initial_lr)\n",
    "scheduler_1 = LambdaLR(optimizer_1, lr_lambda=LRPolicy)\n",
    "\n",
    "print(\"init lr\", optimizer_1.defaults['lr'])\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    # train\n",
    "    optimizer_1.zero_grad()\n",
    "    optimizer_1.step()\n",
    "    print(\"lr of %dth epoch: %f\" % (epoch, optimizer_1.param_groups[0]['lr']))\n",
    "    scheduler_1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "path='../aegnn_results/training_results/latest'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "else:\n",
    "    # clean\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (path, e.strerror))\n",
    "    \n",
    "    # rebuild\n",
    "    os.makedirs(path)\n",
    "\n",
    "src_model = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/checkpoints/ncars/recognition/*/*.pt'), key=os.path.getctime)[-1]\n",
    "dst_model = os.path.join(path,'latest_model.pt')\n",
    "\n",
    "src_log = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/debug/*'), key=os.path.getctime)[-1]\n",
    "dst_log = os.path.join(path,'latest.log')\n",
    "\n",
    "print(src_model,dst_model,src_log,dst_log)\n",
    "try:\n",
    "    shutil.copy2(src_model, dst_model)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "try:\n",
    "    shutil.copy2(src_log, dst_log)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cmd = 'python3 ../../test_bkgnd.py'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4], edge_attr=[1, 3], pos=[3, 3])\n",
      "Data(x=[2, 1], edge_index=[2, 2], edge_attr=[1, 3], pos=[2, 3])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "tensor([[0, 1, 1, 2, 3, 4],\n",
      "        [1, 0, 2, 1, 4, 3]])\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'dataset', 'input_shape', and 'num_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m g \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m \u001b[39m# net1 = GraphRes(2,4)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# model_file = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20221125084923/epoch=99-step=20299.pt'\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m# net1 = torch.load(model_file).to(torch.device('cuda'))\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m net1 \u001b[39m=\u001b[39m aegnn\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mnetworks\u001b[39m.\u001b[39;49mgraph_res\u001b[39m.\u001b[39;49mGraphRes()\n\u001b[1;32m     42\u001b[0m out1 \u001b[39m=\u001b[39m net1(g1)\n\u001b[1;32m     43\u001b[0m out2 \u001b[39m=\u001b[39m net1(g2)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'dataset', 'input_shape', and 'num_outputs'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import aegnn\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "\n",
    "class GraphRes(torch.nn.Module):\n",
    "    def __init__(self, cin, cout):\n",
    "        super(GraphRes, self).__init__()\n",
    "        self.conv1 = GCNConv(cin, cout)\n",
    "\n",
    "    def forward(self, data: torch_geometric.data.Batch) -> torch.Tensor:\n",
    "        data.x = self.conv1(data.x, data.edge_index)\n",
    "        return data\n",
    "\n",
    "edge_attr = torch.tensor([[0.0,0.0,0.0]])\n",
    "\n",
    "edge_index1 = torch.tensor([[0,1,1,2],[1,0,2,1]], dtype=torch.long)\n",
    "x1 = torch.tensor([[1.0],[2.0],[3.0]])\n",
    "pos1 = torch.tensor([0.,0.,0., 1.,1.,0., 2.,0.,0.]).view(3,3)\n",
    "g1 = torch_geometric.data.Data(x=x1, edge_index=edge_index1, pos=pos1, edge_attr=edge_attr)\n",
    "print(g1)\n",
    "\n",
    "edge_index2 = torch.tensor([[0,1],[1,0]], dtype=torch.long)\n",
    "x2 = torch.tensor([[4.0],[5.0]])\n",
    "pos2 = torch.tensor([0.,0.,1., 1.,1.,1.]).view(2,3)\n",
    "g2 = torch_geometric.data.Data(x=x2, edge_index=edge_index2, pos=pos2, edge_attr=edge_attr)\n",
    "print(g2)\n",
    "\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "print(g.x)\n",
    "print(g.edge_index)\n",
    "print(g.batch)\n",
    "\n",
    "g1 = g1.to(torch.device('cuda'))\n",
    "g2 = g2.to(torch.device('cuda'))\n",
    "g = g.to(torch.device('cuda'))\n",
    "net1 = GraphRes(1,4)\n",
    "# model_file = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20221125084923/epoch=99-step=20299.pt'\n",
    "# net1 = torch.load(model_file).to(torch.device('cuda'))\n",
    "# net1 = aegnn.models.networks.graph_res.GraphRes('ncars',)\n",
    "\n",
    "out1 = net1(g1)\n",
    "out2 = net1(g2)\n",
    "out = net1(g)\n",
    "\n",
    "# for param in net1.parameters():\n",
    "#     print(param)\n",
    "\n",
    "print(out1.x)\n",
    "print(out2.x)\n",
    "print(out.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "``CUDA_VISIBLE_DEVICES=5 wandb agent --count 4 yyfteam/aegnn/yzqyfzg6``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in preprocessing.py, order of calling:\n",
    "\n",
    "``ncars``\n",
    "\n",
    "-> ``event_dm.py: prepare_data(self)`` --> ``_prepare_dataset(self)``\n",
    "\n",
    "--> ``ncaltech101.py: _prepare_dataset(self)`` ---> ``processing()@static (parallel)``\n",
    "\n",
    "---> \n",
    "\n",
    " + ``ncars.py: load()@static``  : from text, read ``[x,y,t,p(0/1)]``\n",
    "  + ``ncars.py: read_label()@static``  : 0=car, 1=background; data.label = name, data.y = value\n",
    " + ``ncars.py: pre_transform(self)`` \n",
    "\n",
    "   -----> \n",
    "   + ``.util.normalization.py: normalize_time()`` : ``t_new = (ts - torch.min(ts)) * beta``, beta: float = 0.5e-5\n",
    "   + ``ncaltech101.py: sub_sampling()@static``\n",
    "\n",
    "    &nbsp;&nbsp; ------>\n",
    "    \n",
    "    &nbsp;&nbsp; + ``from torch_geometric.transforms import FixedPoints``: ``FixedPoints(num=10000, allow_duplicates=False, replace=False)`` : will shuffle and subsample events in a event stream !\n",
    "    \n",
    "   + ``from torch_geometric.nn.pool import radius_graph`` : add edge_index by radius_graph\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [87], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m raw_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/space/yyang22/datasets/data/storage/ncars/training/sequence_0/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39m# raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_1118/'\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39m# load x, pos\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m event_data \u001b[39m=\u001b[39m load(raw_file)\n\u001b[1;32m     34\u001b[0m \u001b[39m# load label name and label value\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m (label \u001b[39m:=\u001b[39m read_label(raw_file)) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn [87], line 16\u001b[0m, in \u001b[0;36mload\u001b[0;34m(raw_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(raw_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Data:\n\u001b[1;32m     15\u001b[0m     events_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(raw_file, \u001b[39m\"\u001b[39m\u001b[39mevents.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     events \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np\u001b[39m.\u001b[39;49mloadtxt(events_file))\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     17\u001b[0m     x, pos \u001b[39m=\u001b[39m events[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:], events[:, :\u001b[39m3\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m Data(x\u001b[39m=\u001b[39mx, pos\u001b[39m=\u001b[39mpos)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "\n",
    "# torch.cuda.set_device(5)\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "def load(raw_file: str) -> Data:\n",
    "    events_file = os.path.join(raw_file, \"events.txt\")\n",
    "    events = torch.from_numpy(np.loadtxt(events_file)).float().cuda()\n",
    "    x, pos = events[:, -1:], events[:, :3]\n",
    "    return Data(x=x, pos=pos)\n",
    "\n",
    "def read_label(raw_file: str) -> Optional[Union[str, List[str]]]:\n",
    "    label_file = os.path.join(raw_file, \"is_car.txt\")\n",
    "    with open(label_file, \"r\") as f:\n",
    "        label_txt = f.read().replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    return \"car\" if label_txt == \"1\" else \"background\"\n",
    "\n",
    "\n",
    "class_dict = {class_id: i for i, class_id in enumerate([\"car\", \"background\"])}  # here, car=0, background=1. I dont know why...\n",
    "raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_0/'\n",
    "# raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_1118/'\n",
    "\n",
    "# load x, pos\n",
    "event_data = load(raw_file)\n",
    "\n",
    "# load label name and label value\n",
    "if (label := read_label(raw_file)) is not None:\n",
    "    event_data.label = label if isinstance(label, list) else [label]\n",
    "    event_data.y = torch.tensor([class_dict[label] for label in event_data.label])\n",
    "\n",
    "print(event_data)\n",
    "print(event_data.x.T)\n",
    "print(event_data.pos)\n",
    "print(event_data.pos[:,-1])\n",
    "print(event_data.label)\n",
    "print(event_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     13\u001b[0m \u001b[39m# event_data = sub_sampling(event_data, 10000, True)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m event_data \u001b[39m=\u001b[39m sub_sampling(event_data, \u001b[39m10000\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(event_data)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(event_data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mT)\n",
      "Cell \u001b[0;32mIn [83], line 10\u001b[0m, in \u001b[0;36msub_sampling\u001b[0;34m(data, n_samples, sub_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(item) \u001b[39mand\u001b[39;00m item\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         data[key] \u001b[39m=\u001b[39m item[sample_idx]\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import FixedPoints\n",
    "def sub_sampling(data: Data, n_samples: int, sub_sample: bool) -> Data:\n",
    "    if sub_sample:\n",
    "        sampler = FixedPoints(num=n_samples, allow_duplicates=False, replace=False)\n",
    "        return sampler(data)\n",
    "    else:\n",
    "        sample_idx = np.arange(n_samples)\n",
    "        for key, item in data:\n",
    "            if torch.is_tensor(item) and item.size(0) != 1:\n",
    "                data[key] = item[sample_idx]\n",
    "        return data\n",
    "\n",
    "# event_data = sub_sampling(event_data, 10000, True)\n",
    "event_data = sub_sampling(event_data, 10000, False)\n",
    "\n",
    "print(event_data)\n",
    "print(event_data.x.T)\n",
    "print(event_data.pos)\n",
    "print(event_data.pos[:,-1])\n",
    "print(event_data.label)\n",
    "print(event_data.y)\n",
    "\n",
    "print(torch.min(event_data.pos[:,-1]))\n",
    "print(torch.max(event_data.pos[:,-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.0000e+00, 1.9000e+01, 1.4963e-07],\n",
      "        [7.0000e+00, 3.6000e+01, 2.1136e-07],\n",
      "        [6.6000e+01, 1.1000e+01, 3.2841e-07],\n",
      "        ...,\n",
      "        [2.5000e+01, 2.7000e+01, 4.7212e-07],\n",
      "        [3.0000e+00, 7.0000e+00, 4.8742e-07],\n",
      "        [2.0000e+00, 1.1000e+01, 2.3369e-07]], device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(79., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(42., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(4.9966e-07, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "event_data.pos[:, 2] = (event_data.pos[:, 2] - torch.min(event_data.pos[:, 2])) * 0.5e-5\n",
    "print(event_data.pos)\n",
    "print(torch.min(event_data.pos[:,0]))\n",
    "print(torch.max(event_data.pos[:,0]))\n",
    "\n",
    "print(torch.min(event_data.pos[:,1]))\n",
    "print(torch.max(event_data.pos[:,1]))\n",
    "\n",
    "print(torch.min(event_data.pos[:,2]))\n",
    "print(torch.max(event_data.pos[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  28,   59,   70,  ..., 4625, 4827, 4907],\n",
      "        [   0,    0,    0,  ..., 6262, 6262, 6262]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn.pool import radius_graph\n",
    "event_data.edge_index = radius_graph(event_data.pos, r=3.0, max_num_neighbors=32)\n",
    "print(event_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6263, 1], pos=[6263, 3], file_id='sequence_0', label=[1], y=[1], edge_index=[2, 190656])\n",
      "tensor([[2.3000e+01, 2.6000e+01, 2.4466e-07],\n",
      "        [3.0000e+01, 3.6000e+01, 1.0063e-07],\n",
      "        [2.0000e+01, 1.7000e+01, 4.7357e-07],\n",
      "        ...,\n",
      "        [4.1000e+01, 9.0000e+00, 3.6295e-08],\n",
      "        [1.9000e+01, 1.9000e+01, 3.9599e-07],\n",
      "        [2.0000e+01, 3.0000e+00, 4.7259e-07]], device='cuda:1')\n",
      "['car']\n",
      "tensor([0], device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(79., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(42., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(4.9966e-07, device='cuda:1')\n",
      "tensor([[2739, 5759, 6107,  ..., 3643, 4029, 1174],\n",
      "        [   0,    0,    0,  ..., 6262, 6262, 6262]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "processed = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_0'\n",
    "data2 = torch.load(processed).to(torch.device('cuda'))\n",
    "print(data2)\n",
    "print(data2.pos)\n",
    "print(data2.label)\n",
    "print(data2.y)\n",
    "print(torch.min(data2.pos[:,0]))\n",
    "print(torch.max(data2.pos[:,0]))\n",
    "\n",
    "print(torch.min(data2.pos[:,1]))\n",
    "print(torch.max(data2.pos[:,1]))\n",
    "\n",
    "print(torch.min(data2.pos[:,2]))\n",
    "print(torch.max(data2.pos[:,2]))\n",
    "print(data2.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 2])\n",
      "\n",
      "tensor([3, 3, 3])\n",
      "tensor([0, 0, 0, 2, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def fixed_voxel_grid(pos: Tensor, full_shape: Tensor, size: Tensor, batch: Tensor = None) -> Tensor:\n",
    "\n",
    "    # device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    # params and check\n",
    "    node_dims = pos.size(1)\n",
    "    num_nodes = pos.size(0)\n",
    "    assert len(full_shape) == node_dims\n",
    "    assert len(size)==node_dims or len(size)==1\n",
    "\n",
    "    # batch is None when a single sample\n",
    "    if batch is None:\n",
    "        batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "\n",
    "    # counting how many grids in each dimension, upward ceiling\n",
    "    num_grids = torch.squeeze(torch.ceil(torch.div(full_shape, size)))\n",
    "\n",
    "    # according to node's pos, calculating its idx (x,y,z,...) in grids\n",
    "    idx = torch.div(pos, size, rounding_mode='floor')\n",
    "    # batch is natually the batch_size idx; transposition for later matmul\n",
    "    idx = torch.cat([idx, batch.view(-1,1)], dim=1).T\n",
    "\n",
    "    # calculating accumulated indices: for grids with (A,B,C,..) voxels idx, and point (x,y,z,...)\n",
    "    # the accumulated indices are: (1,A,AB,ABC,...)\n",
    "    acc_idx = torch.ones(node_dims+1, device=device)\n",
    "    for i in range(node_dims):\n",
    "        acc_idx[i+1] = acc_idx[i] * num_grids[i]\n",
    "\n",
    "    # final index is x*1 + y*A + z*AB + ...., which equals to a vector times the idx\n",
    "    cluster = (acc_idx @ idx).type(torch.long)\n",
    "\n",
    "    return cluster\n",
    "\n",
    "\n",
    "pos = torch.tensor([0.1,0.1, 0.2,0.2, 0.3,0.3, 0.1,0.9], dtype=torch.float).view(-1,2) \n",
    "full_shape = torch.ones(2, dtype=torch.float)\n",
    "size = torch.tensor([0.5,0.5], dtype=torch.float).view(-1,2) \n",
    "# batch = torch.tensor([0,0,1,2], dtype=torch.long)\n",
    "batch = None\n",
    "\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.3,0.3,1, 0.1,0.9,1], dtype=torch.float).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float).view(-1,3)\n",
    "\n",
    "print(fixed_voxel_grid(pos1[:, :2], full_shape, size, batch=batch))\n",
    "print('')\n",
    "print(fixed_voxel_grid(pos2[:, :2], full_shape, size, batch=batch))\n",
    "\n",
    "pos3 = torch.cat([pos1, pos2])\n",
    "batch1 = torch.tensor([0,0,0,0,1,1,1], dtype=torch.long)\n",
    "print(fixed_voxel_grid(pos3[:, :2], full_shape, size, batch=batch1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g=DataBatch(x=[7, 1], edge_index=[2, 6], pos=[7, 3], batch=[7], ptr=[3])\n",
      "\n",
      "g1:\n",
      "cluster=\n",
      "tensor([0, 0, 0, 2])\n",
      "x4_auth=\n",
      "tensor([[ 2.7394,  2.1136,  0.8713,  0.2964],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.7394,  2.1136,  0.8713, -0.4446],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<CppNode<ScatterMax>>)\n",
      "out=\n",
      "tensor([[-0.0794, -0.9388]], grad_fn=<MmBackward0>)\n",
      "\n",
      "g2:\n",
      "cluster=\n",
      "tensor([3, 3, 3])\n",
      "x4_auth=\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.4566, -0.3523, -0.1452,  0.7411]], grad_fn=<CppNode<ScatterMax>>)\n",
      "out=\n",
      "tensor([[0.1921, 0.1566]], grad_fn=<MmBackward0>)\n",
      "\n",
      "g:\n",
      "data.batch=\n",
      "tensor([0, 0, 0, 0, 1, 1, 1])\n",
      "cluster=\n",
      "tensor([0, 0, 0, 2, 7, 7, 7])\n",
      "x4_auth=\n",
      "tensor([[ 2.7394,  2.1136,  0.8713,  0.2964],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.7394,  2.1136,  0.8713, -0.4446],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.4566, -0.3523, -0.1452,  0.7411]], grad_fn=<CppNode<ScatterMax>>)\n",
      "out=\n",
      "tensor([[-0.0794, -0.9388],\n",
      "        [ 0.1921,  0.1566]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "from torch.nn.functional import elu, relu\n",
    "from torch.nn import Dropout, Linear\n",
    "from torch_cluster import grid_cluster\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device  = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "x1 = torch.tensor([1.0, -2.0, 3.0, -4.0], dtype=torch.float, device=device).view(-1,1)\n",
    "x2 = torch.tensor([5.0, -6.0, 7.0,         ], dtype=torch.float, device=device).view(-1,1)\n",
    "\n",
    "edge1 = torch.tensor([0,2,1,3, 2,0,3,1], dtype=torch.long, device=device).view(2,-1)\n",
    "edge2 = torch.tensor([1,2,2,1], dtype=torch.long, device=device).view(2,-1)\n",
    "\n",
    "# in this setting, cluster will give diff result for g1,g2 and g\n",
    "# pos1 = torch.tensor([-0.49,-0.3,0.02, -0.49,-0.1,-0.03, 0.49,-0.1,0.01, 0.49,-0.3,-0.02], dtype=torch.float, device=device).view(-1,3)\n",
    "# pos1 += 0.5\n",
    "# pos2 = torch.tensor([-0.21,-0.49,0.02, -0.21,0.49,-0.03, -0.01,0.49,0.01,              ], dtype=torch.float, device=device).view(-1,3)\n",
    "# pos2 += 0.5\n",
    "\n",
    "# new test\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.3,0.3,1, 0.1,0.9,1], dtype=torch.float, device=device).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float, device=device).view(-1,3)\n",
    "\n",
    "g1 = Data(x=x1, edge_index=edge1, pos=pos1)\n",
    "g2 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g3 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "\n",
    "path1 = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_0'\n",
    "path2 = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_1'\n",
    "\n",
    "aegnn1 = torch.load(path2).to(device)\n",
    "aegnn2 = torch.load(path2).to(device)\n",
    "aegnn_whole = torch_geometric.data.Batch.from_data_list([aegnn1, aegnn2])\n",
    "\n",
    "print(f'g={g}')\n",
    "# print(g.x)\n",
    "# print(g.pos)\n",
    "# print(g.edge_index)\n",
    "# print(g.batch)\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(1, 4)\n",
    "        self.norm1 = BatchNorm(in_channels=4)\n",
    "        self.act   = elu\n",
    "\n",
    "        self.batch_size = 2\n",
    "        self.grid_div = 2\n",
    "        self.num_grid = self.grid_div*self.grid_div\n",
    "        # self.size=([1.0/self.grid_div,1.0/self.grid_div])\n",
    "        self.size = torch.tensor([0.5,0.5])\n",
    "        self.full_shape = torch.tensor([1.0,1.0])\n",
    "\n",
    "\n",
    "        self.pool = MaxPoolingX(self.size, size=self.num_grid)\n",
    "\n",
    "        self.fc =  Linear(4*(self.num_grid), out_features=2, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x1 = data.x = self.conv1(data.x, data.edge_index)\n",
    "        # x2 = data.x = self.norm1(data.x)\n",
    "        x2 = data.x\n",
    "        # x3 = data.x = self.act(data.x)\n",
    "        x3 = data.x\n",
    "\n",
    "        # print(f'x1=\\n{x1}')\n",
    "        # print(f'x2=\\n{x2}')\n",
    "        # print(f'x3=\\n{x3}')\n",
    "\n",
    "        if data.batch is None:\n",
    "            data.batch = torch.zeros(data.num_nodes)\n",
    "        else:\n",
    "            print(f'data.batch=\\n{data.batch}')\n",
    "        \n",
    "        # end = ((data.batch.max().item() + 1.0)*self.num_grid - 1)\n",
    "        # print(f'end={end}')\n",
    "\n",
    "        # cluster = voxel_grid(data.pos[:, :2], batch=data.batch, size=self.size)\n",
    "        cluster = fixed_voxel_grid(data.pos[:, :2], full_shape=self.full_shape, batch=data.batch, size=self.size)\n",
    "\n",
    "        # pos = torch.cat([data.pos[:, :2], data.batch.unsqueeze(-1).type_as(data.pos[:, :2])], dim=-1)\n",
    "        # size = self.size + [1]\n",
    "        # print(size)\n",
    "        # size = torch.tensor(size, dtype=pos.dtype, device=pos.device)\n",
    "        # start = torch.tensor([0.0,0.0,0.0], dtype=pos.dtype, device=pos.device)\n",
    "        # end = torch.tensor([1.0,1.0,1.0], dtype=pos.dtype, device=pos.device)\n",
    "        # cluster = grid_cluster(pos, size, start, end)\n",
    "\n",
    "        x4_auth, _ = max_pool_x(cluster, data.x, data.batch, size=self.num_grid)\n",
    "\n",
    "        print(f'cluster=\\n{cluster}')\n",
    "        print(f'x4_auth=\\n{x4_auth}')\n",
    "\n",
    "        x4_aegnn = self.pool(data.x, pos=data.pos[:, :2], batch=data.batch)\n",
    "        # print(f'x4_aegnn=\\n{x4_aegnn}')\n",
    "        # print(f'same={torch.allclose(x4_auth, x4_aegnn)}')\n",
    "\n",
    "        x5 = x4_auth.view(-1, self.fc.in_features)\n",
    "        # print(f'x5=\\n{x5}')\n",
    "        out = self.fc(x5)\n",
    "        print(f'out=\\n{out}')\n",
    "\n",
    "        return out\n",
    "\n",
    "net  = Net()\n",
    "net.eval()\n",
    "\n",
    "print('\\ng1:')\n",
    "g1_out = net(g1)\n",
    "print('\\ng2:')\n",
    "g2_out = net(g2)\n",
    "print('\\ng:')\n",
    "g_out = net(g)\n",
    "\n",
    "# print('\\naegnn1:')\n",
    "# aegnn1_out = net(aegnn1)\n",
    "# print('\\naegnn2:')\n",
    "# aegnn2_out = net(aegnn2)\n",
    "# print('\\naegnn_whole:')\n",
    "# aegnn_whole_out = net(aegnn_whole)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 4, 6, 6])\n",
      "tensor([[2.0000, 1.1000],\n",
      "        [4.0000, 3.1000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [5.0000, 5.1000],\n",
      "        [0.0000, 0.0000],\n",
      "        [7.0000, 7.1000],\n",
      "        [0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "\n",
    "batch_size = 2\n",
    "grid_div = 2\n",
    "num_grid = grid_div*grid_div\n",
    "cluster = voxel_grid(g.pos[:, :2], batch=g.batch, size=([1.0/grid_div,1.0/grid_div]))\n",
    "x, _ = max_pool_x(cluster, g.x, g.batch, size=num_grid)\n",
    "# zero = torch.tensor([0,0,0,0,0,0,0])\n",
    "# x, _ = max_pool_x(zero, g.x, g.batch, size=num_grid)\n",
    "# x, _ = max_pool_x(cluster, g.x, g.batch)\n",
    "\n",
    "\n",
    "# x_new = x.view(batch_size, g.x.shape[1]*num_grid)\n",
    "\n",
    "print(cluster)\n",
    "print(x)\n",
    "# print(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.3892, 2.6133],\n",
      "        [8.5804, 4.4811]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Dropout, Linear, ReLU\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "fc = Linear(g.x.shape[1]*num_grid, out_features=2, bias=False)\n",
    "output = fc(x_new)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5000, -0.5000],\n",
      "        [ 6.0000,  6.1000]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "# gmp = global_max_pool\n",
    "gmp = global_mean_pool\n",
    "x_ori_output = gmp(g.x, batch=g.batch)\n",
    "print(x_ori_output)\n",
    "# fc_ori = Linear(g.x.shape[1], out_features=2, bias=False)\n",
    "# output_ori = fc_ori(x_ori_output)\n",
    "# print(x_ori_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aegnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9439450e489ce535473a2847795b2c81cbeeccb2f39d71287859ebd0392d6b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
