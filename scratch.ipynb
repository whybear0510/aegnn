{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('aegnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n aegnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning.metrics.functional as pl_metrics\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import subgraph\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import elu\n",
    "from torch_geometric.nn.conv import SplineConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 134.74224981457488, avg_Mflop_per_ev = 0.03368556245364372\n",
    "dense: std acc_Mflop_per_ev = 1170.527851753108, std avg_Mflop_per_ev = 0.29263196293827703\n",
    "```\n",
    "\n",
    "For 100 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 3.414027443525552, avg_Mflop_per_ev = 0.034140274435255524\n",
    "dense: std acc_Mflop_per_ev = 28.595094207357473, std avg_Mflop_per_ev = 0.28595094207357474\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected formula for calculating FLOPS (according to updated paper), leading to:\n",
    "\n",
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 240.93893365788432, avg_Mflop_per_ev = 0.06023473341447108\n",
    "dense: std acc_Mflop_per_ev = 2096.876591199398, std avg_Mflop_per_ev = 0.5242191477998495\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('aegnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n aegnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data_module = aegnn.datasets.NCars(batch_size=1, shuffle=False)\n",
    "data_module.setup()\n",
    "dm = data_module.train_dataset\n",
    "\n",
    "# cnt = 0\n",
    "# for i, dms in enumerate(dm):\n",
    "#     cnt += 1\n",
    "#     print(i)\n",
    "\n",
    "# print(cnt)\n",
    "\n",
    "# num_trials=100\n",
    "# nodes=[]\n",
    "# nodes_cnt=0\n",
    "# for index in tqdm(range(num_trials)):\n",
    "#     sample = dm[index % len(dm)]\n",
    "#     nodes.append(sample.num_nodes)\n",
    "#     nodes_cnt += sample.num_nodes\n",
    "# print(nodes_cnt)\n",
    "\n",
    "print(dm.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if add async code into train.py\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_epoch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end  \n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'make_model_asynchronous.<locals>.async_forward'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if I use wandb:\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)  \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)   \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_e\n",
    "poch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end\n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'Settings._validator_factory.<locals>.helper'\n",
    "```\n",
    "Problems seem to be at logger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb import sdk as wandb_sdk\n",
    "\n",
    "wandb.init(project=\"aegnn\", entity=\"yyfteam\")\n",
    "# log_settings = wandb.Settings(start_method=\"thread\")\n",
    "log_settings = wandb.Settings(start_method=\"fork\")\n",
    "wandb_sdk.Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.transforms.cartesian.Cartesian'>\n"
     ]
    }
   ],
   "source": [
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "edge_attr = torch_geometric.transforms.Cartesian(cat=False, max_value=10.0)\n",
    "\n",
    "print(type(edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init lr 0.5\n",
      "lr of 1th epoch: 0.500000\n",
      "lr of 2th epoch: 0.500000\n",
      "lr of 3th epoch: 0.050000\n",
      "lr of 4th epoch: 0.050000\n",
      "lr of 5th epoch: 0.050000\n",
      "lr of 6th epoch: 0.050000\n",
      "lr of 7th epoch: 0.050000\n",
      "lr of 8th epoch: 0.050000\n",
      "lr of 9th epoch: 0.050000\n",
      "lr of 10th epoch: 0.050000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "initial_lr = 0.5\n",
    "\n",
    "\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "net_1 = model()\n",
    "\n",
    "def LRPolicy(epoch):\n",
    "    if epoch < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.1\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(net_1.parameters(), lr = initial_lr)\n",
    "scheduler_1 = LambdaLR(optimizer_1, lr_lambda=LRPolicy)\n",
    "\n",
    "print(\"init lr\", optimizer_1.defaults['lr'])\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    # train\n",
    "    optimizer_1.zero_grad()\n",
    "    optimizer_1.step()\n",
    "    print(\"lr of %dth epoch: %f\" % (epoch, optimizer_1.param_groups[0]['lr']))\n",
    "    scheduler_1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/space/yyang22/datasets/data/scratch/checkpoints/ncars/recognition/20221121142631/epoch=99-step=81099.pt ../aegnn_results/training_results/latest/latest_model.pt /space/yyang22/datasets/data/scratch/debug/20221121-142631.log ../aegnn_results/training_results/latest/latest.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "path='../aegnn_results/training_results/latest'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "else:\n",
    "    # clean\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (path, e.strerror))\n",
    "    \n",
    "    # rebuild\n",
    "    os.makedirs(path)\n",
    "\n",
    "src_model = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/checkpoints/ncars/recognition/*/*.pt'), key=os.path.getctime)[-1]\n",
    "dst_model = os.path.join(path,'latest_model.pt')\n",
    "\n",
    "src_log = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/debug/*'), key=os.path.getctime)[-1]\n",
    "dst_log = os.path.join(path,'latest.log')\n",
    "\n",
    "print(src_model,dst_model,src_log,dst_log)\n",
    "try:\n",
    "    shutil.copy2(src_model, dst_model)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "try:\n",
    "    shutil.copy2(src_log, dst_log)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is started:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 8/100 [00:24<04:36,  3.00s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cmd = 'python3 ../../test_bkgnd.py'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=5 wandb agent --count 4 yyfteam/aegnn/yzqyfzg6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aegnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9439450e489ce535473a2847795b2c81cbeeccb2f39d71287859ebd0392d6b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
