{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning.metrics.functional as pl_metrics\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import subgraph\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import elu\n",
    "from torch_geometric.nn.conv import SplineConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 134.74224981457488, avg_Mflop_per_ev = 0.03368556245364372\n",
    "dense: std acc_Mflop_per_ev = 1170.527851753108, std avg_Mflop_per_ev = 0.29263196293827703\n",
    "```\n",
    "\n",
    "For 100 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 3.414027443525552, avg_Mflop_per_ev = 0.034140274435255524\n",
    "dense: std acc_Mflop_per_ev = 28.595094207357473, std avg_Mflop_per_ev = 0.28595094207357474\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected formula for calculating FLOPS (according to updated paper), leading to:\n",
    "\n",
    "For 4000 samples, wrt their own events/nodes:\n",
    "```\n",
    "acc_Mflop_per_ev = 240.93893365788432, avg_Mflop_per_ev = 0.06023473341447108\n",
    "dense: std acc_Mflop_per_ev = 2096.876591199398, std avg_Mflop_per_ev = 0.5242191477998495\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = aegnn.datasets.NCars(batch_size=1, shuffle=False)\n",
    "data_module.setup()\n",
    "dm = data_module.train_dataset\n",
    "\n",
    "# cnt = 0\n",
    "# for i, dms in enumerate(dm):\n",
    "#     cnt += 1\n",
    "#     print(i)\n",
    "\n",
    "# print(cnt)\n",
    "\n",
    "# num_trials=100\n",
    "# nodes=[]\n",
    "# nodes_cnt=0\n",
    "# for index in tqdm(range(num_trials)):\n",
    "#     sample = dm[index % len(dm)]\n",
    "#     nodes.append(sample.num_nodes)\n",
    "#     nodes_cnt += sample.num_nodes\n",
    "# print(nodes_cnt)\n",
    "\n",
    "print(dm.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if add async code into train.py\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_epoch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end  \n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'make_model_asynchronous.<locals>.async_forward'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if I use wandb:\n",
    "```\n",
    "File \"scripts/train.py\", line 97, in <module>\n",
    "    main(arguments)\n",
    "  File \"scripts/train.py\", line 91, in main\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
    "    self._run(model)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
    "    self._dispatch()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
    "    self.accelerator.start_training(self)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
    "    self.training_type_plugin.start_training(trainer)  \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in \n",
    "start_training\n",
    "    self._results = trainer.run_stage()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
    "    return self._run_train()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
    "    self.fit_loop.run()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
    "    self.advance(*args, **kwargs)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
    "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
    "    output = self.on_run_end()\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 235, in on_run_end\n",
    "    self._on_train_epoch_end_hook(processed_outputs)   \n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 276, in _on_train_e\n",
    "poch_end_hook\n",
    "    trainer_hook(processed_epoch_output)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 109, in on_train_epoch_end\n",
    "    callback.on_train_epoch_end(self, self.lightning_module)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 310, in on_train_epoch_end\n",
    "    self.save_checkpoint(trainer)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 386, in save_checkpoint\n",
    "    self._save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 742, in _save_none_monitor_checkpoint\n",
    "    self._save_model(trainer, filepath)\n",
    "  File \"/users/yyang22/thesis/aegnn_project/aegnn/aegnn/utils/callbacks/checkpoint_full_model.py\", line 14, in _save_model\n",
    "    torch.save(trainer.model, filepath)\n",
    "File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
    "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
    "  File \"/users/yyang22/anaconda3/envs/aegnn/lib/python3.8/site-packages/torch/serialization.py\", line 589, in _save\n",
    "    pickler.dump(obj)\n",
    "AttributeError: Can't pickle local object 'Settings._validator_factory.<locals>.helper'\n",
    "```\n",
    "Problems seem to be at logger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb import sdk as wandb_sdk\n",
    "\n",
    "wandb.init(project=\"aegnn\", entity=\"yyfteam\")\n",
    "# log_settings = wandb.Settings(start_method=\"thread\")\n",
    "log_settings = wandb.Settings(start_method=\"fork\")\n",
    "wandb_sdk.Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aegnn\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "edge_attr = torch_geometric.transforms.Cartesian(cat=False, max_value=10.0)\n",
    "\n",
    "print(type(edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "initial_lr = 0.5\n",
    "\n",
    "\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "net_1 = model()\n",
    "\n",
    "def LRPolicy(epoch):\n",
    "    if epoch < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.1\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(net_1.parameters(), lr = initial_lr)\n",
    "scheduler_1 = LambdaLR(optimizer_1, lr_lambda=LRPolicy)\n",
    "\n",
    "print(\"init lr\", optimizer_1.defaults['lr'])\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    # train\n",
    "    optimizer_1.zero_grad()\n",
    "    optimizer_1.step()\n",
    "    print(\"lr of %dth epoch: %f\" % (epoch, optimizer_1.param_groups[0]['lr']))\n",
    "    scheduler_1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "path='../aegnn_results/training_results/latest'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "else:\n",
    "    # clean\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (path, e.strerror))\n",
    "    \n",
    "    # rebuild\n",
    "    os.makedirs(path)\n",
    "\n",
    "src_model = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/checkpoints/ncars/recognition/*/*.pt'), key=os.path.getctime)[-1]\n",
    "dst_model = os.path.join(path,'latest_model.pt')\n",
    "\n",
    "src_log = sorted(glob.glob(r'/space/yyang22/datasets/data/scratch/debug/*'), key=os.path.getctime)[-1]\n",
    "dst_log = os.path.join(path,'latest.log')\n",
    "\n",
    "print(src_model,dst_model,src_log,dst_log)\n",
    "try:\n",
    "    shutil.copy2(src_model, dst_model)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "try:\n",
    "    shutil.copy2(src_log, dst_log)\n",
    "except IOError as e:\n",
    "    print(\"Unable to copy file. %s\" % e)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cmd = 'python3 ../../test_bkgnd.py'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4], edge_attr=[1, 3], pos=[3, 3])\n",
      "Data(x=[2, 1], edge_index=[2, 2], edge_attr=[1, 3], pos=[2, 3])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "tensor([[0, 1, 1, 2, 3, 4],\n",
      "        [1, 0, 2, 1, 4, 3]])\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'dataset', 'input_shape', and 'num_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m g \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m \u001b[39m# net1 = GraphRes(2,4)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# model_file = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20221125084923/epoch=99-step=20299.pt'\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m# net1 = torch.load(model_file).to(torch.device('cuda'))\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m net1 \u001b[39m=\u001b[39m aegnn\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mnetworks\u001b[39m.\u001b[39;49mgraph_res\u001b[39m.\u001b[39;49mGraphRes()\n\u001b[1;32m     42\u001b[0m out1 \u001b[39m=\u001b[39m net1(g1)\n\u001b[1;32m     43\u001b[0m out2 \u001b[39m=\u001b[39m net1(g2)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'dataset', 'input_shape', and 'num_outputs'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import aegnn\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "\n",
    "class GraphRes(torch.nn.Module):\n",
    "    def __init__(self, cin, cout):\n",
    "        super(GraphRes, self).__init__()\n",
    "        self.conv1 = GCNConv(cin, cout)\n",
    "\n",
    "    def forward(self, data: torch_geometric.data.Batch) -> torch.Tensor:\n",
    "        data.x = self.conv1(data.x, data.edge_index)\n",
    "        return data\n",
    "\n",
    "edge_attr = torch.tensor([[0.0,0.0,0.0]])\n",
    "\n",
    "edge_index1 = torch.tensor([[0,1,1,2],[1,0,2,1]], dtype=torch.long)\n",
    "x1 = torch.tensor([[1.0],[2.0],[3.0]])\n",
    "pos1 = torch.tensor([0.,0.,0., 1.,1.,0., 2.,0.,0.]).view(3,3)\n",
    "g1 = torch_geometric.data.Data(x=x1, edge_index=edge_index1, pos=pos1, edge_attr=edge_attr)\n",
    "print(g1)\n",
    "\n",
    "edge_index2 = torch.tensor([[0,1],[1,0]], dtype=torch.long)\n",
    "x2 = torch.tensor([[4.0],[5.0]])\n",
    "pos2 = torch.tensor([0.,0.,1., 1.,1.,1.]).view(2,3)\n",
    "g2 = torch_geometric.data.Data(x=x2, edge_index=edge_index2, pos=pos2, edge_attr=edge_attr)\n",
    "print(g2)\n",
    "\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "print(g.x)\n",
    "print(g.edge_index)\n",
    "print(g.batch)\n",
    "\n",
    "g1 = g1.to(torch.device('cuda'))\n",
    "g2 = g2.to(torch.device('cuda'))\n",
    "g = g.to(torch.device('cuda'))\n",
    "net1 = GraphRes(1,4)\n",
    "# model_file = '/users/yyang22/thesis/aegnn_project/aegnn_results/training_results/checkpoints/ncars/recognition/20221125084923/epoch=99-step=20299.pt'\n",
    "# net1 = torch.load(model_file).to(torch.device('cuda'))\n",
    "# net1 = aegnn.models.networks.graph_res.GraphRes('ncars',)\n",
    "\n",
    "out1 = net1(g1)\n",
    "out2 = net1(g2)\n",
    "out = net1(g)\n",
    "\n",
    "# for param in net1.parameters():\n",
    "#     print(param)\n",
    "\n",
    "print(out1.x)\n",
    "print(out2.x)\n",
    "print(out.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "``CUDA_VISIBLE_DEVICES=5 wandb agent --count 4 yyfteam/aegnn/yzqyfzg6``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in preprocessing.py, order of calling:\n",
    "\n",
    "``ncars``\n",
    "\n",
    "-> ``event_dm.py: prepare_data(self)`` --> ``_prepare_dataset(self)``\n",
    "\n",
    "--> ``ncaltech101.py: _prepare_dataset(self)`` ---> ``processing()@static (parallel)``\n",
    "\n",
    "---> \n",
    "\n",
    " + ``ncars.py: load()@static``  : from text, read ``[x,y,t,p(0/1)]``\n",
    "  + ``ncars.py: read_label()@static``  : 0=car, 1=background; data.label = name, data.y = value\n",
    " + ``ncars.py: pre_transform(self)`` \n",
    "\n",
    "   -----> \n",
    "   + ``.util.normalization.py: normalize_time()`` : ``t_new = (ts - torch.min(ts)) * beta``, beta: float = 0.5e-5\n",
    "   + ``ncaltech101.py: sub_sampling()@static``\n",
    "\n",
    "    &nbsp;&nbsp; ------>\n",
    "    \n",
    "    &nbsp;&nbsp; + ``from torch_geometric.transforms import FixedPoints``: ``FixedPoints(num=10000, allow_duplicates=False, replace=False)`` : will shuffle and subsample events in a event stream !\n",
    "    \n",
    "   + ``from torch_geometric.nn.pool import radius_graph`` : add edge_index by radius_graph\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [87], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m raw_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/space/yyang22/datasets/data/storage/ncars/training/sequence_0/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39m# raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_1118/'\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39m# load x, pos\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m event_data \u001b[39m=\u001b[39m load(raw_file)\n\u001b[1;32m     34\u001b[0m \u001b[39m# load label name and label value\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m (label \u001b[39m:=\u001b[39m read_label(raw_file)) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn [87], line 16\u001b[0m, in \u001b[0;36mload\u001b[0;34m(raw_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(raw_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Data:\n\u001b[1;32m     15\u001b[0m     events_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(raw_file, \u001b[39m\"\u001b[39m\u001b[39mevents.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     events \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np\u001b[39m.\u001b[39;49mloadtxt(events_file))\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     17\u001b[0m     x, pos \u001b[39m=\u001b[39m events[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:], events[:, :\u001b[39m3\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m Data(x\u001b[39m=\u001b[39mx, pos\u001b[39m=\u001b[39mpos)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "\n",
    "# torch.cuda.set_device(5)\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "def load(raw_file: str) -> Data:\n",
    "    events_file = os.path.join(raw_file, \"events.txt\")\n",
    "    events = torch.from_numpy(np.loadtxt(events_file)).float().cuda()\n",
    "    x, pos = events[:, -1:], events[:, :3]\n",
    "    return Data(x=x, pos=pos)\n",
    "\n",
    "def read_label(raw_file: str) -> Optional[Union[str, List[str]]]:\n",
    "    label_file = os.path.join(raw_file, \"is_car.txt\")\n",
    "    with open(label_file, \"r\") as f:\n",
    "        label_txt = f.read().replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    return \"car\" if label_txt == \"1\" else \"background\"\n",
    "\n",
    "\n",
    "class_dict = {class_id: i for i, class_id in enumerate([\"car\", \"background\"])}  # here, car=0, background=1. I dont know why...\n",
    "raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_0/'\n",
    "# raw_file = '/space/yyang22/datasets/data/storage/ncars/training/sequence_1118/'\n",
    "\n",
    "# load x, pos\n",
    "event_data = load(raw_file)\n",
    "\n",
    "# load label name and label value\n",
    "if (label := read_label(raw_file)) is not None:\n",
    "    event_data.label = label if isinstance(label, list) else [label]\n",
    "    event_data.y = torch.tensor([class_dict[label] for label in event_data.label])\n",
    "\n",
    "print(event_data)\n",
    "print(event_data.x.T)\n",
    "print(event_data.pos)\n",
    "print(event_data.pos[:,-1])\n",
    "print(event_data.label)\n",
    "print(event_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     13\u001b[0m \u001b[39m# event_data = sub_sampling(event_data, 10000, True)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m event_data \u001b[39m=\u001b[39m sub_sampling(event_data, \u001b[39m10000\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(event_data)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(event_data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mT)\n",
      "Cell \u001b[0;32mIn [83], line 10\u001b[0m, in \u001b[0;36msub_sampling\u001b[0;34m(data, n_samples, sub_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(item) \u001b[39mand\u001b[39;00m item\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         data[key] \u001b[39m=\u001b[39m item[sample_idx]\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import FixedPoints\n",
    "def sub_sampling(data: Data, n_samples: int, sub_sample: bool) -> Data:\n",
    "    if sub_sample:\n",
    "        sampler = FixedPoints(num=n_samples, allow_duplicates=False, replace=False)\n",
    "        return sampler(data)\n",
    "    else:\n",
    "        sample_idx = np.arange(n_samples)\n",
    "        for key, item in data:\n",
    "            if torch.is_tensor(item) and item.size(0) != 1:\n",
    "                data[key] = item[sample_idx]\n",
    "        return data\n",
    "\n",
    "# event_data = sub_sampling(event_data, 10000, True)\n",
    "event_data = sub_sampling(event_data, 10000, False)\n",
    "\n",
    "print(event_data)\n",
    "print(event_data.x.T)\n",
    "print(event_data.pos)\n",
    "print(event_data.pos[:,-1])\n",
    "print(event_data.label)\n",
    "print(event_data.y)\n",
    "\n",
    "print(torch.min(event_data.pos[:,-1]))\n",
    "print(torch.max(event_data.pos[:,-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.0000e+00, 1.9000e+01, 1.4963e-07],\n",
      "        [7.0000e+00, 3.6000e+01, 2.1136e-07],\n",
      "        [6.6000e+01, 1.1000e+01, 3.2841e-07],\n",
      "        ...,\n",
      "        [2.5000e+01, 2.7000e+01, 4.7212e-07],\n",
      "        [3.0000e+00, 7.0000e+00, 4.8742e-07],\n",
      "        [2.0000e+00, 1.1000e+01, 2.3369e-07]], device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(79., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(42., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(4.9966e-07, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "event_data.pos[:, 2] = (event_data.pos[:, 2] - torch.min(event_data.pos[:, 2])) * 0.5e-5\n",
    "print(event_data.pos)\n",
    "print(torch.min(event_data.pos[:,0]))\n",
    "print(torch.max(event_data.pos[:,0]))\n",
    "\n",
    "print(torch.min(event_data.pos[:,1]))\n",
    "print(torch.max(event_data.pos[:,1]))\n",
    "\n",
    "print(torch.min(event_data.pos[:,2]))\n",
    "print(torch.max(event_data.pos[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  28,   59,   70,  ..., 4625, 4827, 4907],\n",
      "        [   0,    0,    0,  ..., 6262, 6262, 6262]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn.pool import radius_graph\n",
    "event_data.edge_index = radius_graph(event_data.pos, r=3.0, max_num_neighbors=32)\n",
    "print(event_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6263, 1], pos=[6263, 3], file_id='sequence_0', label=[1], y=[1], edge_index=[2, 190656])\n",
      "tensor([[2.3000e+01, 2.6000e+01, 2.4466e-07],\n",
      "        [3.0000e+01, 3.6000e+01, 1.0063e-07],\n",
      "        [2.0000e+01, 1.7000e+01, 4.7357e-07],\n",
      "        ...,\n",
      "        [4.1000e+01, 9.0000e+00, 3.6295e-08],\n",
      "        [1.9000e+01, 1.9000e+01, 3.9599e-07],\n",
      "        [2.0000e+01, 3.0000e+00, 4.7259e-07]], device='cuda:1')\n",
      "['car']\n",
      "tensor([0], device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(79., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(42., device='cuda:1')\n",
      "tensor(0., device='cuda:1')\n",
      "tensor(4.9966e-07, device='cuda:1')\n",
      "tensor([[2739, 5759, 6107,  ..., 3643, 4029, 1174],\n",
      "        [   0,    0,    0,  ..., 6262, 6262, 6262]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "processed = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_0'\n",
    "data2 = torch.load(processed).to(torch.device('cuda'))\n",
    "print(data2)\n",
    "print(data2.pos)\n",
    "print(data2.label)\n",
    "print(data2.y)\n",
    "print(torch.min(data2.pos[:,0]))\n",
    "print(torch.max(data2.pos[:,0]))\n",
    "\n",
    "print(torch.min(data2.pos[:,1]))\n",
    "print(torch.max(data2.pos[:,1]))\n",
    "\n",
    "print(torch.min(data2.pos[:,2]))\n",
    "print(torch.max(data2.pos[:,2]))\n",
    "print(data2.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 2])\n",
      "\n",
      "tensor([3, 3, 3])\n",
      "tensor([0, 0, 0, 2, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def fixed_voxel_grid(pos: Tensor, full_shape: Tensor, size: Tensor, batch: Tensor = None) -> Tensor:\n",
    "\n",
    "    # device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    # params and check\n",
    "    node_dims = pos.size(1)\n",
    "    num_nodes = pos.size(0)\n",
    "    assert len(full_shape) == node_dims\n",
    "    assert len(size)==node_dims or len(size)==1\n",
    "\n",
    "    # batch is None when a single sample\n",
    "    if batch is None:\n",
    "        batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "\n",
    "    # counting how many grids in each dimension, upward ceiling\n",
    "    num_grids = torch.squeeze(torch.ceil(torch.div(full_shape, size)))\n",
    "\n",
    "    # according to node's pos, calculating its idx (x,y,z,...) in grids\n",
    "    idx = torch.div(pos, size, rounding_mode='floor')\n",
    "    # batch is natually the batch_size idx; transposition for later matmul\n",
    "    idx = torch.cat([idx, batch.view(-1,1)], dim=1).T\n",
    "\n",
    "    # calculating accumulated indices: for grids with (A,B,C,..) voxels idx, and point (x,y,z,...)\n",
    "    # the accumulated indices are: (1,A,AB,ABC,...)\n",
    "    acc_idx = torch.ones(node_dims+1, device=device)\n",
    "    for i in range(node_dims):\n",
    "        acc_idx[i+1] = acc_idx[i] * num_grids[i]\n",
    "\n",
    "    # final index is x*1 + y*A + z*AB + ...., which equals to a vector times the idx\n",
    "    cluster = (acc_idx @ idx).type(torch.long)\n",
    "\n",
    "    return cluster\n",
    "\n",
    "\n",
    "pos = torch.tensor([0.1,0.1, 0.2,0.2, 0.3,0.3, 0.1,0.9], dtype=torch.float).view(-1,2) \n",
    "full_shape = torch.ones(2, dtype=torch.float)\n",
    "size = torch.tensor([0.5,0.5], dtype=torch.float).view(-1,2) \n",
    "# batch = torch.tensor([0,0,1,2], dtype=torch.long)\n",
    "batch = None\n",
    "\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.3,0.3,1, 0.1,0.9,1], dtype=torch.float).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float).view(-1,3)\n",
    "\n",
    "print(fixed_voxel_grid(pos1[:, :2], full_shape, size, batch=batch))\n",
    "print('')\n",
    "print(fixed_voxel_grid(pos2[:, :2], full_shape, size, batch=batch))\n",
    "\n",
    "pos3 = torch.cat([pos1, pos2])\n",
    "batch1 = torch.tensor([0,0,0,0,1,1,1], dtype=torch.long)\n",
    "print(fixed_voxel_grid(pos3[:, :2], full_shape, size, batch=batch1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3250, 1], pos=[3250, 3], file_id='sequence_1', label=[1], y=[1], edge_index=[2, 66166])\n",
      "g=DataBatch(x=[7, 1], edge_index=[2, 6], pos=[7, 3], batch=[7], ptr=[3])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'img_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 131\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mout=\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mout\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    129\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m--> 131\u001b[0m net  \u001b[39m=\u001b[39m Net()\n\u001b[1;32m    132\u001b[0m net\u001b[39m.\u001b[39meval()\n\u001b[1;32m    134\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mg1:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 81\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.5\u001b[39m,\u001b[39m0.5\u001b[39m])\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_shape \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.0\u001b[39m,\u001b[39m1.0\u001b[39m])\n\u001b[0;32m---> 81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool \u001b[39m=\u001b[39m MaxPoolingX(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_grid)\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m  Linear(\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_grid), out_features\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'img_shape'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "from torch.nn.functional import elu, relu\n",
    "from torch.nn import Dropout, Linear\n",
    "from torch_cluster import grid_cluster\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device  = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "x1 = torch.tensor([1.0, -2.0, 3.0, -4.0], dtype=torch.float, device=device).view(-1,1)\n",
    "x2 = torch.tensor([5.0, -6.0, 7.0,         ], dtype=torch.float, device=device).view(-1,1)\n",
    "\n",
    "edge1 = torch.tensor([0,2,1,3, 2,0,3,1], dtype=torch.long, device=device).view(2,-1)\n",
    "edge2 = torch.tensor([1,2,2,1], dtype=torch.long, device=device).view(2,-1)\n",
    "\n",
    "# in this setting, cluster will give diff result for g1,g2 and g\n",
    "# pos1 = torch.tensor([-0.49,-0.3,0.02, -0.49,-0.1,-0.03, 0.49,-0.1,0.01, 0.49,-0.3,-0.02], dtype=torch.float, device=device).view(-1,3)\n",
    "# pos1 += 0.5\n",
    "# pos2 = torch.tensor([-0.21,-0.49,0.02, -0.21,0.49,-0.03, -0.01,0.49,0.01,              ], dtype=torch.float, device=device).view(-1,3)\n",
    "# pos2 += 0.5\n",
    "\n",
    "# new test\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.3,0.3,1, 0.1,0.9,1], dtype=torch.float, device=device).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float, device=device).view(-1,3)\n",
    "\n",
    "g1 = Data(x=x1, edge_index=edge1, pos=pos1)\n",
    "g2 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g3 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "\n",
    "path1 = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_0'\n",
    "path2 = '/space/yyang22/datasets/data/storage/ncars/processed/training/sequence_1'\n",
    "\n",
    "aegnn1 = torch.load(path2).to(device)\n",
    "aegnn2 = torch.load(path2).to(device)\n",
    "aegnn_whole = torch_geometric.data.Batch.from_data_list([aegnn1, aegnn2])\n",
    "print(aegnn1)\n",
    "\n",
    "print(f'g={g}')\n",
    "# print(g.x)\n",
    "# print(g.pos)\n",
    "# print(g.edge_index)\n",
    "# print(g.batch)\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(1, 4)\n",
    "        self.norm1 = BatchNorm(in_channels=4)\n",
    "        self.act   = elu\n",
    "\n",
    "        self.batch_size = 2\n",
    "        self.grid_div = 2\n",
    "        self.num_grid = self.grid_div*self.grid_div\n",
    "        # self.size=([1.0/self.grid_div,1.0/self.grid_div])\n",
    "        self.size = torch.tensor([0.5,0.5])\n",
    "        self.full_shape = torch.tensor([1.0,1.0])\n",
    "\n",
    "\n",
    "        self.pool = MaxPoolingX(self.size, size=self.num_grid)\n",
    "\n",
    "        self.fc =  Linear(4*(self.num_grid), out_features=2, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x1 = data.x = self.conv1(data.x, data.edge_index)\n",
    "        # x2 = data.x = self.norm1(data.x)\n",
    "        x2 = data.x\n",
    "        # x3 = data.x = self.act(data.x)\n",
    "        x3 = data.x\n",
    "\n",
    "        # print(f'x1=\\n{x1}')\n",
    "        # print(f'x2=\\n{x2}')\n",
    "        # print(f'x3=\\n{x3}')\n",
    "\n",
    "        if data.batch is None:\n",
    "            data.batch = torch.zeros(data.num_nodes)\n",
    "        else:\n",
    "            print(f'data.batch=\\n{data.batch}')\n",
    "        \n",
    "        # end = ((data.batch.max().item() + 1.0)*self.num_grid - 1)\n",
    "        # print(f'end={end}')\n",
    "\n",
    "        # cluster = voxel_grid(data.pos[:, :2], batch=data.batch, size=self.size)\n",
    "        cluster = fixed_voxel_grid(data.pos[:, :2], full_shape=self.full_shape, batch=data.batch, size=self.size)\n",
    "\n",
    "        # pos = torch.cat([data.pos[:, :2], data.batch.unsqueeze(-1).type_as(data.pos[:, :2])], dim=-1)\n",
    "        # size = self.size + [1]\n",
    "        # print(size)\n",
    "        # size = torch.tensor(size, dtype=pos.dtype, device=pos.device)\n",
    "        # start = torch.tensor([0.0,0.0,0.0], dtype=pos.dtype, device=pos.device)\n",
    "        # end = torch.tensor([1.0,1.0,1.0], dtype=pos.dtype, device=pos.device)\n",
    "        # cluster = grid_cluster(pos, size, start, end)\n",
    "\n",
    "        x4_auth, _ = max_pool_x(cluster, data.x, data.batch, size=self.num_grid)\n",
    "\n",
    "        print(f'cluster=\\n{cluster}')\n",
    "        print(f'x4_auth=\\n{x4_auth}')\n",
    "\n",
    "        x4_aegnn = self.pool(data.x, pos=data.pos[:, :2], batch=data.batch)\n",
    "        # print(f'x4_aegnn=\\n{x4_aegnn}')\n",
    "        # print(f'same={torch.allclose(x4_auth, x4_aegnn)}')\n",
    "\n",
    "        x5 = x4_auth.view(-1, self.fc.in_features)\n",
    "        # print(f'x5=\\n{x5}')\n",
    "        out = self.fc(x5)\n",
    "        print(f'out=\\n{out}')\n",
    "\n",
    "        return out\n",
    "\n",
    "net  = Net()\n",
    "net.eval()\n",
    "\n",
    "print('\\ng1:')\n",
    "g1_out = net(g1)\n",
    "print('\\ng2:')\n",
    "g2_out = net(g2)\n",
    "print('\\ng:')\n",
    "g_out = net(g)\n",
    "\n",
    "# print('\\naegnn1:')\n",
    "# aegnn1_out = net(aegnn1)\n",
    "# print('\\naegnn2:')\n",
    "# aegnn2_out = net(aegnn2)\n",
    "# print('\\naegnn_whole:')\n",
    "# aegnn_whole_out = net(aegnn_whole)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 4, 6, 6])\n",
      "tensor([[2.0000, 1.1000],\n",
      "        [4.0000, 3.1000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [5.0000, 5.1000],\n",
      "        [0.0000, 0.0000],\n",
      "        [7.0000, 7.1000],\n",
      "        [0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "\n",
    "batch_size = 2\n",
    "grid_div = 2\n",
    "num_grid = grid_div*grid_div\n",
    "cluster = voxel_grid(g.pos[:, :2], batch=g.batch, size=([1.0/grid_div,1.0/grid_div]))\n",
    "x, _ = max_pool_x(cluster, g.x, g.batch, size=num_grid)\n",
    "# zero = torch.tensor([0,0,0,0,0,0,0])\n",
    "# x, _ = max_pool_x(zero, g.x, g.batch, size=num_grid)\n",
    "# x, _ = max_pool_x(cluster, g.x, g.batch)\n",
    "\n",
    "\n",
    "# x_new = x.view(batch_size, g.x.shape[1]*num_grid)\n",
    "\n",
    "print(cluster)\n",
    "print(x)\n",
    "# print(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.3892, 2.6133],\n",
      "        [8.5804, 4.4811]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Dropout, Linear, ReLU\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "fc = Linear(g.x.shape[1]*num_grid, out_features=2, bias=False)\n",
    "output = fc(x_new)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5000, -0.5000],\n",
      "        [ 6.0000,  6.1000]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "# gmp = global_max_pool\n",
    "gmp = global_mean_pool\n",
    "x_ori_output = gmp(g.x, batch=g.batch)\n",
    "print(x_ori_output)\n",
    "# fc_ori = Linear(g.x.shape[1], out_features=2, bias=False)\n",
    "# output_ori = fc_ori(x_ori_output)\n",
    "# print(x_ori_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3, 1], edge_index=[2, 6], pos=[3, 3])\n",
      "tensor([[ 1.],\n",
      "        [ 3.],\n",
      "        [-4.]])\n",
      "tensor([[0, 0, 1, 1, 2, 2],\n",
      "        [1, 2, 0, 2, 0, 1]])\n",
      "tensor([[0.1500, 0.1500, 1.0000],\n",
      "        [0.1000, 0.6000, 1.0000],\n",
      "        [0.6000, 0.6000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x, max_pool\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "from torch.nn.functional import elu, relu\n",
    "from torch.nn import Dropout, Linear\n",
    "from torch_cluster import grid_cluster\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device  = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "x1 = torch.tensor([1.0, -2.0, 3.0, -4.0], dtype=torch.float, device=device).view(-1,1)\n",
    "x2 = torch.tensor([5.0, -6.0, 7.0,         ], dtype=torch.float, device=device).view(-1,1)\n",
    "\n",
    "edge1 = torch.tensor([0,3,1,2,2,3, 3,0,2,1,3,2], dtype=torch.long, device=device).view(2,-1)\n",
    "edge2 = torch.tensor([1,2,2,1], dtype=torch.long, device=device).view(2,-1)\n",
    "\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.1,0.6,1, 0.6,0.6,1], dtype=torch.float, device=device).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float, device=device).view(-1,3)\n",
    "\n",
    "g1 = Data(x=x1, edge_index=edge1, pos=pos1)\n",
    "g2 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g3 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "\n",
    "batch_size = 2\n",
    "grid_div = 2\n",
    "num_grid = grid_div*grid_div\n",
    "cluster = voxel_grid(g1.pos[:, :2], batch=g1.batch, size=([1.0/grid_div,1.0/grid_div]))\n",
    "data = max_pool(cluster, g1)\n",
    "\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.edge_index)\n",
    "print(data.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 1], edge_index=[2, 6], pos=[4, 3])\n",
      "tensor([1.0000, 1.0000, 0.5831, 0.5831, 0.7071, 0.7071])\n",
      "edge_attr=tensor([], size=(6, 0))\n",
      "Data(x=[4, 1], edge_index=[2, 6], pos=[4, 3], edge_attr=[6, 0], edge_weight=[6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import aegnn\n",
    "import os\n",
    "from typing import Callable, List, Optional, Union\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.transforms import Cartesian, Distance\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "\n",
    "from aegnn.models.layer import MaxPooling, MaxPoolingX\n",
    "from torch_geometric.nn.pool import max_pool_x, voxel_grid, avg_pool_x, max_pool\n",
    "from torch_geometric.nn import GCNConv, Sequential, global_max_pool,global_mean_pool\n",
    "from torch.nn.functional import elu, relu\n",
    "from torch.nn import Dropout, Linear\n",
    "from torch_cluster import grid_cluster\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device  = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "x1 = torch.tensor([1.0, -2.0, 3.0, -4.0], dtype=torch.float, device=device).view(-1,1)\n",
    "x2 = torch.tensor([5.0, -6.0, 7.0,         ], dtype=torch.float, device=device).view(-1,1)\n",
    "\n",
    "edge1 = torch.tensor([0,3,1,2,2,3, 3,0,2,1,3,2], dtype=torch.long, device=device).view(2,-1)\n",
    "edge2 = torch.tensor([1,2,2,1], dtype=torch.long, device=device).view(2,-1)\n",
    "\n",
    "pos1 = torch.tensor([0.1,0.1,1, 0.2,0.2,1, 0.1,0.6,1, 0.6,0.6,1], dtype=torch.float, device=device).view(-1,3)\n",
    "pos2 = torch.tensor([0.6,0.6,1, 0.7,0.7,1, 0.8,0.8,1], dtype=torch.float, device=device).view(-1,3)\n",
    "\n",
    "g1 = Data(x=x1, edge_index=edge1, pos=pos1)\n",
    "g2 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g3 = Data(x=x2, edge_index=edge2, pos=pos2)\n",
    "g = torch_geometric.data.Batch.from_data_list([g1,g2])\n",
    "\n",
    "print(g1)\n",
    "\n",
    "# trans2 = Cartesian()\n",
    "\n",
    "# g1 = trans2(g1)\n",
    "\n",
    "trans = Distance()\n",
    "g1 = trans(g1)\n",
    "g1.edge_weight = g1.edge_attr[:,-1]\n",
    "g1.edge_attr = g1.edge_attr[:, :-1]\n",
    "\n",
    "print(g1.edge_weight)\n",
    "print(f'edge_attr={g1.edge_attr}')\n",
    "print(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CUDA_VISIBLE_DEVICES=2 wandb agent yyfteam/aegnn/l8y4mj6f\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt('/users/yyang22/thesis/aegnn_project/aegnn_results/async_accuracy.csv', delimiter=',')\n",
    "plt.plot(data[:9000,0], data[:9000,1])\n",
    "\n",
    "plt.savefig('/users/yyang22/thesis/aegnn_project/aegnn_results/async_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (4, 18), (12, 23), (19, 22), (19, 24), (22, 24)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "# from torch import tensor\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import k_hop_subgraph, remove_self_loops, to_networkx\n",
    "\n",
    "a = torch.tensor([False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,True,False,True]).view(-1,1)\n",
    "b=torch.unique(torch.nonzero(a)[:,0])\n",
    "# print(b)  #tensor([12, 23, 25])\n",
    "idx_update = b\n",
    "module_asy_graph_edge_index = torch.tensor([[ 3,  0, 18, 23,  4, 22, 24, 19, 24, 12, 19, 22],\n",
    "                                            [ 0,  3,  4, 12, 18, 19, 19, 22, 22, 23, 24, 24]])\n",
    "pos  = torch.tensor([[5.4000e+01, 5.2000e+01, 0.0000e+00],\n",
    "        [5.7000e+01, 4.0000e+00, 7.0000e-10],\n",
    "        [5.3000e+01, 3.3000e+01, 7.0500e-10],\n",
    "        [5.4000e+01, 5.1000e+01, 7.4500e-10],\n",
    "        [5.8000e+01, 9.0000e+00, 9.1000e-10],\n",
    "        [5.7000e+01, 2.3000e+01, 9.2500e-10],\n",
    "        [5.0000e+01, 4.7000e+01, 9.3000e-10],\n",
    "        [4.9000e+01, 0.0000e+00, 9.5500e-10],\n",
    "        [1.1000e+02, 5.4000e+01, 9.8000e-10],\n",
    "        [5.1000e+01, 5.4000e+01, 9.8000e-10],\n",
    "        [5.7000e+01, 1.7000e+01, 1.1150e-09],\n",
    "        [4.9000e+01, 5.8000e+01, 1.1200e-09],\n",
    "        [5.7000e+01, 1.3000e+01, 1.1250e-09],\n",
    "        [5.3000e+01, 5.7000e+01, 1.1450e-09],\n",
    "        [5.1000e+01, 4.0000e+01, 1.2400e-09],\n",
    "        [5.0000e+01, 6.2000e+01, 1.2500e-09],\n",
    "        [5.7000e+01, 2.0000e+01, 1.5850e-09],\n",
    "        [5.5000e+01, 4.3000e+01, 1.5900e-09],\n",
    "        [5.8000e+01, 1.0000e+01, 1.6000e-09],\n",
    "        [1.0600e+02, 5.2000e+01, 1.6400e-09],\n",
    "        [5.3000e+01, 6.1000e+01, 1.8250e-09],\n",
    "        [1.0200e+02, 6.3000e+01, 1.8350e-09],\n",
    "        [1.0500e+02, 5.3000e+01, 1.8900e-09],\n",
    "        [5.8000e+01, 1.3000e+01, 2.3500e-09],\n",
    "        [1.0600e+02, 5.2000e+01, 2.3850e-09],\n",
    "        [5.6000e+01, 1.4000e+01, 2.4000e-09]])\n",
    "data = Data(x=torch.zeros(26),edge_index=module_asy_graph_edge_index, pos=pos[:,:2])\n",
    "pos_list = pos[:,:2].tolist()\n",
    "\n",
    "g = to_networkx(data, to_undirected=True)\n",
    "print(g.edges)\n",
    "nx.draw_networkx(g, with_labels=True,  node_size=0, node_shape='.',  font_size=8, font_color='k',  edge_color='b', width=1)\n",
    "# nx.draw_networkx_edges(g, pos = pos_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 23, 25])\n",
      "tensor([[23, 12],\n",
      "        [12, 23]])\n",
      "tensor([0, 1, 2])\n",
      "tensor([False, False, False,  True, False, False, False, False, False,  True,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nodes_in_subgraph, edges_connected, nodes_new_location, connected_edges_mask = k_hop_subgraph(idx_update, num_hops=1,\n",
    "                                                                edge_index=module_asy_graph_edge_index,\n",
    "                                                                num_nodes=26)\n",
    "print(nodes_in_subgraph)\n",
    "print(edges_connected)\n",
    "print(nodes_new_location)\n",
    "print(connected_edges_mask) # original edge_index --- connected_edges_mask ---> edges_connected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 23, 25],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.nonzero(a).T\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 39.1152,  35.1283,  59.0085,  34.5254,  31.2570,  77.9295,  90.6091,\n",
      "          56.0357,  36.3456,  49.0102,  49.0918,   8.0623,  31.2570,  31.4006,\n",
      "          38.0132,  84.3090,  69.6348,  76.3217,  14.7648,  20.5913,  74.1080,\n",
      "          38.8330,   7.0711,   3.1623,  65.0000,  62.0725,  67.1193,  22.4722,\n",
      "           2.2361,   5.3852,  43.0465,   9.0554,  95.1893,  62.8172,  27.6586,\n",
      "          21.9317,  20.0250,  39.8497,  33.9706,  34.3657,   5.0000, 103.1213,\n",
      "          10.0000,  47.0425,  26.4764,  29.6142,  67.0075,  38.4187,  51.4782,\n",
      "          13.6015,  85.0000,  68.7314,  36.3593,  52.2015,  71.1758,   0.0000]])\n"
     ]
    }
   ],
   "source": [
    "pos_all = torch.tensor([[6.5000e+01, 7.8000e+01, 0.0000e+00],\n",
    "        [6.9000e+01, 7.8000e+01, 0.0000e+00],\n",
    "        [4.5000e+01, 7.6000e+01, 0.0000e+00],\n",
    "        [7.0000e+01, 6.9000e+01, 5.0000e-12],\n",
    "        [1.0000e+02, 4.4000e+01, 1.0000e-11],\n",
    "        [2.7000e+01, 6.3000e+01, 1.4500e-10],\n",
    "        [1.5000e+01, 5.8000e+01, 1.7500e-10],\n",
    "        [1.0600e+02, 1.9000e+01, 1.9000e-10],\n",
    "        [1.0900e+02, 3.9000e+01, 6.6000e-10],\n",
    "        [1.0300e+02, 2.6000e+01, 7.0500e-10],\n",
    "        [1.0100e+02, 2.6000e+01, 7.0500e-10],\n",
    "        [1.0000e+02, 6.8000e+01, 1.0400e-09],\n",
    "        [1.0000e+02, 4.4000e+01, 1.0700e-09],\n",
    "        [1.0900e+02, 4.4000e+01, 1.0750e-09],\n",
    "        [8.2000e+01, 4.4000e+01, 1.0750e-09],\n",
    "        [2.6000e+01, 4.3000e+01, 1.0750e-09],\n",
    "        [4.7000e+01, 3.5000e+01, 1.0800e-09],\n",
    "        [3.9000e+01, 3.5000e+01, 1.0800e-09],\n",
    "        [9.7000e+01, 6.2000e+01, 1.0850e-09],\n",
    "        [9.4000e+01, 5.7000e+01, 1.4150e-09],\n",
    "        [1.0800e+02, 1.0000e+00, 1.7300e-09],\n",
    "        [9.6000e+01, 3.7000e+01, 1.8750e-09],\n",
    "        [9.9000e+01, 7.0000e+01, 1.9500e-09],\n",
    "        [1.0300e+02, 7.2000e+01, 2.0000e-09],\n",
    "        [1.0400e+02, 1.0000e+01, 2.0150e-09],\n",
    "        [1.0700e+02, 1.3000e+01, 2.0950e-09],\n",
    "        [1.0800e+02, 8.0000e+00, 2.1050e-09],\n",
    "        [8.5000e+01, 6.3000e+01, 2.1150e-09],\n",
    "        [1.0300e+02, 7.3000e+01, 2.3800e-09],\n",
    "        [9.9000e+01, 7.3000e+01, 2.3800e-09],\n",
    "        [1.0200e+02, 3.2000e+01, 2.4000e-09],\n",
    "        [9.5000e+01, 7.4000e+01, 2.4050e-09],\n",
    "        [1.0000e+01, 6.0000e+01, 2.5500e-09],\n",
    "        [4.3000e+01, 6.0000e+01, 2.5500e-09],\n",
    "        [9.8000e+01, 4.8000e+01, 2.5550e-09],\n",
    "        [8.4000e+01, 6.6000e+01, 2.5650e-09],\n",
    "        [8.4000e+01, 7.6000e+01, 2.5800e-09],\n",
    "        [9.2000e+01, 3.7000e+01, 2.5850e-09],\n",
    "        [8.1000e+01, 5.0000e+01, 3.3100e-09],\n",
    "        [7.0000e+01, 7.0000e+01, 3.3250e-09],\n",
    "        [1.0400e+02, 7.0000e+01, 3.3250e-09],\n",
    "        [1.0000e+00, 7.0000e+01, 3.3250e-09],\n",
    "        [9.6000e+01, 6.9000e+01, 3.3250e-09],\n",
    "        [1.0200e+02, 2.8000e+01, 3.3350e-09],\n",
    "        [1.0900e+02, 4.9000e+01, 3.3400e-09],\n",
    "        [9.8000e+01, 4.6000e+01, 3.6700e-09],\n",
    "        [3.7000e+01, 7.6000e+01, 3.6750e-09],\n",
    "        [7.4000e+01, 5.1000e+01, 3.8800e-09],\n",
    "        [1.1100e+02, 2.4000e+01, 4.1100e-09],\n",
    "        [1.0000e+02, 6.2000e+01, 4.3400e-09],\n",
    "        [6.4000e+01, 0.0000e+00, 4.3500e-09],\n",
    "        [9.4000e+01, 7.0000e+00, 4.7700e-09],\n",
    "        [7.3000e+01, 5.6000e+01, 4.7800e-09],\n",
    "        [5.5000e+01, 5.7000e+01, 4.7850e-09],\n",
    "        [1.0900e+02, 4.0000e+00, 4.7900e-09],\n",
    "        [1.0400e+02, 7.5000e+01, 4.8150e-09]])\n",
    "pos_new = torch.tensor([[1.0400e+02, 7.5000e+01, 4.8150e-09]])\n",
    "distance = torch.cdist(pos_all, pos_new)\n",
    "print(distance.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "connected_node_mask = torch.cdist(pos_all, pos_new) <= 3.0\n",
    "print(connected_node_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 39.2428,  35.2704,  59.0593,  34.6699,  31.3688,  77.9872,  90.6532,\n",
      "          56.1249,  36.4143,  49.1121,  49.1935,   8.4853,  31.3688,  31.4960,\n",
      "          38.1576,  84.3564,  69.6850,  76.3675,  15.0997,  20.8327,  74.1485,\n",
      "          38.9102,   7.7460,   4.0000,  65.0846,  62.1128,  67.1714,  22.5832,\n",
      "           3.1623,   5.8310,  43.1741,   9.5917,  95.2260,  62.8649,  27.8568,\n",
      "          22.1811,  20.1990,  39.9249,  34.1174,  34.4674,   6.0000, 103.1504,\n",
      "          10.2956,  47.1593,  26.5707,  29.7321,  67.0522,  38.4968,  51.5364,\n",
      "          14.0000,  85.0412,  68.8041,  36.4417,  52.2877,  71.2180,   3.7417]])\n"
     ]
    }
   ],
   "source": [
    "tmp = torch.tensor([[ 39.2428],\n",
    "        [ 35.2704],\n",
    "        [ 59.0593],\n",
    "        [ 34.6699],\n",
    "        [ 31.3688],\n",
    "        [ 77.9872],\n",
    "        [ 90.6532],\n",
    "        [ 56.1249],\n",
    "        [ 36.4143],\n",
    "        [ 49.1121],\n",
    "        [ 49.1935],\n",
    "        [  8.4853],\n",
    "        [ 31.3688],\n",
    "        [ 31.4960],\n",
    "        [ 38.1576],\n",
    "        [ 84.3564],\n",
    "        [ 69.6850],\n",
    "        [ 76.3675],\n",
    "        [ 15.0997],\n",
    "        [ 20.8327],\n",
    "        [ 74.1485],\n",
    "        [ 38.9102],\n",
    "        [  7.7460],\n",
    "        [  4.0000],\n",
    "        [ 65.0846],\n",
    "        [ 62.1128],\n",
    "        [ 67.1714],\n",
    "        [ 22.5832],\n",
    "        [  3.1623],\n",
    "        [  5.8310],\n",
    "        [ 43.1741],\n",
    "        [  9.5917],\n",
    "        [ 95.2260],\n",
    "        [ 62.8649],\n",
    "        [ 27.8568],\n",
    "        [ 22.1811],\n",
    "        [ 20.1990],\n",
    "        [ 39.9249],\n",
    "        [ 34.1174],\n",
    "        [ 34.4674],\n",
    "        [  6.0000],\n",
    "        [103.1504],\n",
    "        [ 10.2956],\n",
    "        [ 47.1593],\n",
    "        [ 26.5707],\n",
    "        [ 29.7321],\n",
    "        [ 67.0522],\n",
    "        [ 38.4968],\n",
    "        [ 51.5364],\n",
    "        [ 14.0000],\n",
    "        [ 85.0412],\n",
    "        [ 68.8041],\n",
    "        [ 36.4417],\n",
    "        [ 52.2877],\n",
    "        [ 71.2180],\n",
    "        [  3.7417]])\n",
    "print(tmp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 39.1152,  35.1283,  59.0085,  34.5254,  31.2570,  77.9295,  90.6090,\n",
      "         56.0357,  36.3456,  49.0102,  49.0918,   8.0623,  31.2570,  31.4006,\n",
      "         38.0132,  84.3090,  69.6348,  76.3217,  14.7648,  20.5913,  74.1080,\n",
      "         38.8330,   7.0711,   3.1623,  65.0000,  62.0725,  67.1193,  22.4722,\n",
      "          2.2361,   5.3852,  43.0465,   9.0554,  95.1893,  62.8172,  27.6586,\n",
      "         21.9317,  20.0250,  39.8497,  33.9706,  34.3657,   5.0000, 103.1213,\n",
      "         10.0000,  47.0425,  26.4764,  29.6142,  67.0075,  38.4187,  51.4781,\n",
      "         13.6015,  85.0000,  68.7314,  36.3593,  52.2015,  71.1758,   0.0000],\n",
      "       device='cuda:0')\n",
      "tensor([ 39.2428,  35.2704,  59.0593,  34.6699,  31.3688,  77.9872,  90.6532,\n",
      "         56.1249,  36.4143,  49.1121,  49.1935,   8.4853,  31.3688,  31.4960,\n",
      "         38.1576,  84.3564,  69.6850,  76.3675,  15.0997,  20.8327,  74.1485,\n",
      "         38.9102,   7.7460,   4.0000,  65.0846,  62.1128,  67.1714,  22.5832,\n",
      "          3.1623,   5.8310,  43.1741,   9.5917,  95.2260,  62.8649,  27.8568,\n",
      "         22.1811,  20.1990,  39.9249,  34.1174,  34.4674,   6.0000, 103.1504,\n",
      "         10.2956,  47.1593,  26.5707,  29.7321,  67.0522,  38.4968,  51.5364,\n",
      "         14.0000,  85.0412,  68.8041,  36.4417,  52.2877,  71.2180,   3.7417],\n",
      "       device='cuda:0')\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda:0'\n",
    "test_pos_all = torch.tensor([[6.5000e+01, 7.8000e+01, 0.0000e+00],\n",
    "        [6.9000e+01, 7.8000e+01, 0.0000e+00],\n",
    "        [4.5000e+01, 7.6000e+01, 0.0000e+00],\n",
    "        [7.0000e+01, 6.9000e+01, 5.0000e-12],\n",
    "        [1.0000e+02, 4.4000e+01, 1.0000e-11],\n",
    "        [2.7000e+01, 6.3000e+01, 1.4500e-10],\n",
    "        [1.5000e+01, 5.8000e+01, 1.7500e-10],\n",
    "        [1.0600e+02, 1.9000e+01, 1.9000e-10],\n",
    "        [1.0900e+02, 3.9000e+01, 6.6000e-10],\n",
    "        [1.0300e+02, 2.6000e+01, 7.0500e-10],\n",
    "        [1.0100e+02, 2.6000e+01, 7.0500e-10],\n",
    "        [1.0000e+02, 6.8000e+01, 1.0400e-09],\n",
    "        [1.0000e+02, 4.4000e+01, 1.0700e-09],\n",
    "        [1.0900e+02, 4.4000e+01, 1.0750e-09],\n",
    "        [8.2000e+01, 4.4000e+01, 1.0750e-09],\n",
    "        [2.6000e+01, 4.3000e+01, 1.0750e-09],\n",
    "        [4.7000e+01, 3.5000e+01, 1.0800e-09],\n",
    "        [3.9000e+01, 3.5000e+01, 1.0800e-09],\n",
    "        [9.7000e+01, 6.2000e+01, 1.0850e-09],\n",
    "        [9.4000e+01, 5.7000e+01, 1.4150e-09],\n",
    "        [1.0800e+02, 1.0000e+00, 1.7300e-09],\n",
    "        [9.6000e+01, 3.7000e+01, 1.8750e-09],\n",
    "        [9.9000e+01, 7.0000e+01, 1.9500e-09],\n",
    "        [1.0300e+02, 7.2000e+01, 2.0000e-09],\n",
    "        [1.0400e+02, 1.0000e+01, 2.0150e-09],\n",
    "        [1.0700e+02, 1.3000e+01, 2.0950e-09],\n",
    "        [1.0800e+02, 8.0000e+00, 2.1050e-09],\n",
    "        [8.5000e+01, 6.3000e+01, 2.1150e-09],\n",
    "        [1.0300e+02, 7.3000e+01, 2.3800e-09],\n",
    "        [9.9000e+01, 7.3000e+01, 2.3800e-09],\n",
    "        [1.0200e+02, 3.2000e+01, 2.4000e-09],\n",
    "        [9.5000e+01, 7.4000e+01, 2.4050e-09],\n",
    "        [1.0000e+01, 6.0000e+01, 2.5500e-09],\n",
    "        [4.3000e+01, 6.0000e+01, 2.5500e-09],\n",
    "        [9.8000e+01, 4.8000e+01, 2.5550e-09],\n",
    "        [8.4000e+01, 6.6000e+01, 2.5650e-09],\n",
    "        [8.4000e+01, 7.6000e+01, 2.5800e-09],\n",
    "        [9.2000e+01, 3.7000e+01, 2.5850e-09],\n",
    "        [8.1000e+01, 5.0000e+01, 3.3100e-09],\n",
    "        [7.0000e+01, 7.0000e+01, 3.3250e-09],\n",
    "        [1.0400e+02, 7.0000e+01, 3.3250e-09],\n",
    "        [1.0000e+00, 7.0000e+01, 3.3250e-09],\n",
    "        [9.6000e+01, 6.9000e+01, 3.3250e-09],\n",
    "        [1.0200e+02, 2.8000e+01, 3.3350e-09],\n",
    "        [1.0900e+02, 4.9000e+01, 3.3400e-09],\n",
    "        [9.8000e+01, 4.6000e+01, 3.6700e-09],\n",
    "        [3.7000e+01, 7.6000e+01, 3.6750e-09],\n",
    "        [7.4000e+01, 5.1000e+01, 3.8800e-09],\n",
    "        [1.1100e+02, 2.4000e+01, 4.1100e-09],\n",
    "        [1.0000e+02, 6.2000e+01, 4.3400e-09],\n",
    "        [6.4000e+01, 0.0000e+00, 4.3500e-09],\n",
    "        [9.4000e+01, 7.0000e+00, 4.7700e-09],\n",
    "        [7.3000e+01, 5.6000e+01, 4.7800e-09],\n",
    "        [5.5000e+01, 5.7000e+01, 4.7850e-09],\n",
    "        [1.0900e+02, 4.0000e+00, 4.7900e-09],\n",
    "        [1.0400e+02, 7.5000e+01, 4.8150e-09]], device=device)\n",
    "test_pos_new = torch.tensor([[1.0400e+02, 7.5000e+01, 4.8150e-09]], device=device)\n",
    "\n",
    "\n",
    "pos_diff_sqrt = (test_pos_all-test_pos_new).pow(2).sum(1).sqrt()\n",
    "print(pos_diff_sqrt)\n",
    "\n",
    "test_node_dis = torch.cdist(test_pos_all, test_pos_new, p=2).T.squeeze()\n",
    "print(test_node_dis)\n",
    "#! cuda:0 is wrong! cpu is right!!!\n",
    "\n",
    "# pdist = torch.nn.PairwiseDistance(p=2)\n",
    "# test_node_dis = pdist(test_pos_all, test_pos_new)\n",
    "# print(test_node_dis)\n",
    "\n",
    "\n",
    "print(torch.allclose(test_node_dis, pos_diff_sqrt, atol=1e-5))\n",
    "\n",
    "\n",
    "# from_code_node_dis = torch.tensor([[ 39.2428],\n",
    "#         [ 35.2704],\n",
    "#         [ 59.0593],\n",
    "#         [ 34.6699],\n",
    "#         [ 31.3688],\n",
    "#         [ 77.9872],\n",
    "#         [ 90.6532],\n",
    "#         [ 56.1249],\n",
    "#         [ 36.4143],\n",
    "#         [ 49.1121],\n",
    "#         [ 49.1935],\n",
    "#         [  8.4853],\n",
    "#         [ 31.3688],\n",
    "#         [ 31.4960],\n",
    "#         [ 38.1576],\n",
    "#         [ 84.3564],\n",
    "#         [ 69.6850],\n",
    "#         [ 76.3675],\n",
    "#         [ 15.0997],\n",
    "#         [ 20.8327],\n",
    "#         [ 74.1485],\n",
    "#         [ 38.9102],\n",
    "#         [  7.7460],\n",
    "#         [  4.0000],\n",
    "#         [ 65.0846],\n",
    "#         [ 62.1128],\n",
    "#         [ 67.1714],\n",
    "#         [ 22.5832],\n",
    "#         [  3.1623],\n",
    "#         [  5.8310],\n",
    "#         [ 43.1741],\n",
    "#         [  9.5917],\n",
    "#         [ 95.2260],\n",
    "#         [ 62.8649],\n",
    "#         [ 27.8568],\n",
    "#         [ 22.1811],\n",
    "#         [ 20.1990],\n",
    "#         [ 39.9249],\n",
    "#         [ 34.1174],\n",
    "#         [ 34.4674],\n",
    "#         [  6.0000],\n",
    "#         [103.1504],\n",
    "#         [ 10.2956],\n",
    "#         [ 47.1593],\n",
    "#         [ 26.5707],\n",
    "#         [ 29.7321],\n",
    "#         [ 67.0522],\n",
    "#         [ 38.4968],\n",
    "#         [ 51.5364],\n",
    "#         [ 14.0000],\n",
    "#         [ 85.0412],\n",
    "#         [ 68.8041],\n",
    "#         [ 36.4417],\n",
    "#         [ 52.2877],\n",
    "#         [ 71.2180],\n",
    "#         [  3.7417]])\n",
    "# # print(from_code_node_dis.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "diff = tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "a = torch.sum(diff, dim=1)\n",
    "b = torch.nonzero(a)[:, 0]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sync, graph:\n",
      "after conv1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1059, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0834, 0.0146],\n",
      "        [0.1061, 0.0217]], grad_fn=<DivBackward0>)\n",
      "\n",
      "after elu1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1059, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0834, 0.0146],\n",
      "        [0.1061, 0.0217]], grad_fn=<EluBackward0>)\n",
      "\n",
      "after conv2:\n",
      "tensor([[-0.0053, -0.0028, -0.0182,  0.0049],\n",
      "        [-0.0037, -0.0015, -0.0118,  0.0021],\n",
      "        [-0.0054, -0.0018, -0.0167,  0.0023],\n",
      "        [-0.0062, -0.0020, -0.0142,  0.0010],\n",
      "        [-0.0050, -0.0020, -0.0152,  0.0027],\n",
      "        [-0.0043, -0.0019, -0.0135,  0.0035],\n",
      "        [-0.0081, -0.0035, -0.0229,  0.0027],\n",
      "        [-0.0058, -0.0022, -0.0161,  0.0025]], grad_fn=<DivBackward0>)\n",
      "\n",
      "sync graph.num_nodes = 8\n",
      "graph:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import aegnn\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, SplineConv, BatchNorm\n",
    "from torch.nn.functional import elu\n",
    "import pytorch_lightning as pl\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "pl.seed_everything(12345)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# def network\n",
    "class net(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = SplineConv(1, 2, dim=2, kernel_size=2, bias=False, root_weight=False)\n",
    "        self.conv2 = SplineConv(2, 4, dim=2, kernel_size=2, bias=False, root_weight=False)\n",
    "        # self.conv1 = GCNConv(1, 2)\n",
    "        # self.conv2 = GCNConv(2, 4)\n",
    "        # self.norm1 = BatchNorm(in_channels=2)\n",
    "        self.act = elu\n",
    "\n",
    "    def forward(self, data):\n",
    "        data.x = self.conv1(data.x, data.edge_index, data.edge_attr)\n",
    "        print(f'after conv1:\\n{data.x}\\n')\n",
    "        data.x = self.act(data.x)\n",
    "        print(f'after elu1:\\n{data.x}\\n')\n",
    "        data.x = self.conv2(data.x, data.edge_index, data.edge_attr)\n",
    "        print(f'after conv2:\\n{data.x}\\n')\n",
    "        return data.x\n",
    "\n",
    "module = net()\n",
    "\n",
    "\n",
    "# def graph for sync\n",
    "attr_func = torch_geometric.transforms.Cartesian(cat=False, max_value=10.0)\n",
    "graph = Data(\n",
    "    x = torch.tensor([1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], device=device).view(-1,1),\n",
    "    pos = torch.tensor([[2,3],[1,2],[1,1],[3,1],[3,2],[5,3],[5,2],[4,2]], device=device),\n",
    "    edge_index = torch.tensor([[0,1,1,2,2,3,3,4,4,0,4,7,7,6,6,5], [1,0,2,1,3,2,4,3,0,4,7,4,6,7,5,6]], device=device, dtype=torch.long))\n",
    "graph = attr_func(graph)\n",
    "print('sync, graph:')\n",
    "output = module.forward(graph)\n",
    "print(f'sync graph.num_nodes = {graph.num_nodes}')\n",
    "print('graph:')\n",
    "g_nx = to_networkx(graph, to_undirected=True)\n",
    "nx.draw_networkx(g_nx, with_labels=True, pos=graph.pos.tolist(), node_size=0, node_shape='.',  font_size=8, font_color='k',  edge_color='b', width=1)\n",
    "\n",
    "# def graph_init, node_x for AEGNN\n",
    "x = torch.tensor([1.0, 0.0, 1.0, 1.0, 1.0], device=device).view(-1,1)\n",
    "edge_index = torch.tensor([[0,1,1,2,2,3,3,4,4,0],\n",
    "                           [1,0,2,1,3,2,4,3,0,4]], device=device, dtype=torch.long)\n",
    "pos = torch.tensor([[2,3],[1,2],[1,1],[3,1],[3,2]], device=device)\n",
    "\n",
    "graph_init = Data(x=x, pos=pos, edge_index=edge_index)\n",
    "graph_init = attr_func(graph_init)\n",
    "\n",
    "node_1 = Data(x=torch.tensor([[1.0]], device=device), pos=torch.tensor([[5,3]], device=device))\n",
    "node_2 = Data(x=torch.tensor([[1.0]], device=device), pos=torch.tensor([[5,2]], device=device))\n",
    "node_3 = Data(x=torch.tensor([[1.0]], device=device), pos=torch.tensor([[4,2]], device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "async, init:\n",
      "after conv1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210]], grad_fn=<DivBackward0>)\n",
      "\n",
      "after elu1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210]], grad_fn=<EluBackward0>)\n",
      "\n",
      "after conv2:\n",
      "tensor([[-0.0051, -0.0028, -0.0180,  0.0049],\n",
      "        [-0.0037, -0.0015, -0.0118,  0.0021],\n",
      "        [-0.0054, -0.0018, -0.0167,  0.0023],\n",
      "        [-0.0060, -0.0020, -0.0140,  0.0010],\n",
      "        [-0.0049, -0.0020, -0.0135,  0.0021]], grad_fn=<DivBackward0>)\n",
      "\n",
      "async, add node 1:\n",
      "after conv1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210],\n",
      "        [0.0000, 0.0000]], grad_fn=<CatBackward0>)\n",
      "\n",
      "after elu1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210],\n",
      "        [0.0000, 0.0000]], grad_fn=<EluBackward0>)\n",
      "\n",
      "after conv2:\n",
      "tensor([[-0.0051, -0.0028, -0.0180,  0.0049],\n",
      "        [-0.0037, -0.0015, -0.0118,  0.0021],\n",
      "        [-0.0054, -0.0018, -0.0167,  0.0023],\n",
      "        [-0.0060, -0.0020, -0.0140,  0.0010],\n",
      "        [-0.0049, -0.0020, -0.0135,  0.0021],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<CatBackward0>)\n",
      "\n",
      "async, add node 2:\n",
      "after conv1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0680, 0.0068]], grad_fn=<IndexPutBackward0>)\n",
      "\n",
      "after elu1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1021, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0680, 0.0068]], grad_fn=<EluBackward0>)\n",
      "\n",
      "after conv2:\n",
      "tensor([[-0.0051, -0.0028, -0.0180,  0.0049],\n",
      "        [-0.0037, -0.0015, -0.0118,  0.0021],\n",
      "        [-0.0054, -0.0018, -0.0167,  0.0023],\n",
      "        [-0.0060, -0.0020, -0.0140,  0.0010],\n",
      "        [-0.0049, -0.0020, -0.0135,  0.0021],\n",
      "        [-0.0042, -0.0010, -0.0098,  0.0022],\n",
      "        [-0.0089, -0.0040, -0.0274,  0.0029]], grad_fn=<IndexPutBackward0>)\n",
      "\n",
      "async, add node 3:\n",
      "after conv1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1059, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0834, 0.0146],\n",
      "        [0.1061, 0.0217]], grad_fn=<IndexPutBackward0>)\n",
      "\n",
      "after elu1:\n",
      "tensor([[0.0754, 0.0169],\n",
      "        [0.1102, 0.0223],\n",
      "        [0.0604, 0.0101],\n",
      "        [0.0797, 0.0150],\n",
      "        [0.1059, 0.0210],\n",
      "        [0.1442, 0.0366],\n",
      "        [0.0834, 0.0146],\n",
      "        [0.1061, 0.0217]], grad_fn=<EluBackward0>)\n",
      "\n",
      "after conv2:\n",
      "tensor([[-0.0053, -0.0028, -0.0182,  0.0049],\n",
      "        [-0.0037, -0.0015, -0.0118,  0.0021],\n",
      "        [-0.0054, -0.0018, -0.0167,  0.0023],\n",
      "        [-0.0062, -0.0020, -0.0142,  0.0010],\n",
      "        [-0.0050, -0.0020, -0.0152,  0.0027],\n",
      "        [-0.0043, -0.0019, -0.0135,  0.0035],\n",
      "        [-0.0081, -0.0035, -0.0229,  0.0027],\n",
      "        [-0.0058, -0.0022, -0.0161,  0.0025]], grad_fn=<IndexPutBackward0>)\n",
      "\n",
      "conv2.asy_graph.num_nodes: \n",
      "8\n",
      "graph:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdPElEQVR4nO3deXRV5bnH8d+JERBNguDQxIRJRYugUVpRFNGKONQBL1p7lSujSBnFlEkRoQwCMglCw5QEWuXixNKLLY4XiktwaBaKoEUuM0FBCklABiHn/vEU2ypDhnPOe85+v5+1XIoEeNTg+Wa/ez8nFA6HwwIAAN5Kcj0AAABwixgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOC55PJ8UFlZmYqKipSSkqJQKBTtmQAAQASEw2GVlpYqIyNDSUnH//q/XDFQVFSkrKysiA0HAABiZ8uWLcrMzDzu95crBlJSUr7/yVJTUyMzGQAAiKqSkhJlZWV9/zp+POWKgaNHA6mpqcQAAAAJ5mRH/NxACACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBxMSXX36pFi1aqFGjRrryyiu1Zs0a1yMBQIXVr19fF198sbKzs5Wdna0FCxa4Hikikl0PAD88/PDD6tatmzp27KiXXnpJXbp00fLly12PBQAV9tJLL6lJkyaux4gorgwg6nbs2KHCwkK1b99ektSuXTtt2LBBGzdudDsYAEASMYAY2LJlizIyMpScbBeiQqGQ6tatq82bNzueDAAq7oEHHlDTpk3VtWtX7dy50/U4EUEMICZKS0O6+mqpoMC+HQ6Hnc4DAJXxl7/8RYsXf6K2bQtVvXoddejQwfVIEUEMIOqqV8/Stm1bVVR0WH37Slu2hLVlyxbVrVvX9WgAUCF169bV9u3SyJGn6s47H9GyZctcjxQRxACiKhyWhg49R8nJl6tHjz/qjDOkO+98WfXr11f9+vVdjwcA5bZv3z7t2bPn+2+/8cZ8XX755e4GiiCeJkBU/fd/SwsXSs88M0Pz53eUNForV6Zq+PC5rkcDgAr5+uuv1a5dO+3de0RSWIWFDTVv3jzXY0VEKFyOw9uSkhKlpaWpuLhYqampsZgLAbB9u3TJJdLNN0vz5//z73fpIr34ovTZZxInBQASTWGh1KyZ9Ne/Sldc4XqaEyvv6zfHBIiKcFjq3l2qVk169tl//76JE6W0NKlrV/s4AIBbxACi4rnnpNdek3JzpTp1/v370tKk2bOlt96SZs1yMx8A4J+IAURcUZHUu7f0wANS27bH/pibb5YeekjKyZHYPQQAbhEDiKhwWOrWTapRQ5oy5cQfO368VLu23UNQVhab+QAAP0YMIKLmzpVef12aOdNe6E8kNVWaM0d69107TgAAuEEMIGK2bpX69pUefFC6447y/ZjWre1Gw/79pfXrozsfAODYiAFERDhs9wCccYY0eXLFfuy4cdI550idO3NcAAAuEAOIiLw8afFiezrgzDMr9mNTUuzHL10qTZsWnfkAAMdHDKDKNm+W+vWzr+xvu61yP8cNN0i9ekkDB0rr1kV2PgDAiREDqJJw2JYHpaXZMqGqGDNGSk+XOnXiuAAAYokYQJXMmmXLg2bPtiCoitNPl/LzpffeO/ljiQCAyCEGUGkbN9rSoIcesiVCkXDddfZEwuDB0tq1kfk5AQAnRgygUsrKbFlQ7dq2PCiSRo+WMjOljh2lI0ci+3MDAH6MGECl5ObasqA5c2x5UCTVrCkVFEgrVkiTJkX25wYA/BgxgApbv96WBHXvbkuDouGaa+wJhSFDpM8/j86vAQAwxAAqpKzMHiE85xxbFhRNI0dK9erZccHhw9H9tQDAZ8QAKmTaNFsOlJdny4Ki6bTT7L0OPv5YmjAhur8WAPiMGEC5rVtnS4F69bIlQbFw1VXSb38rDR0qrV4dm18TAHxDDKBcyspsGVB6ui0HiqXhw6Xzz+e4AACihRhAuUyZYsuA8vNtOVAs1ahhTxcUFkb/PgUA8BExgJNau9aWAPXta0uBXLjySjuiGDZMWrXKzQwAEFTEAE7oyBG7PJ+ZacuAXHrySalRI6lDB+m779zOAgBBQgzghCZNsuU/BQW2DMil6tXt6YJPP5WeesrtLAAQJMQAjuvzz23pT79+tgQoHjRrZkcWI0ZIK1e6ngYAgoEYwDEdPmzHA/Xq2fKfePLEE1LjxjbfoUOupwGAxEcM4JgmTLBlP3Pn2vKfeFKtmh1brF4tjRrlehoASHzEAH5k9Wpb8vPb39rSn3h0+eV2hDFqlD1yCACoPGIA/+bo8cD559uyn3j22GNS06b2dMHBg66nAYDERQzg34wbZ19pFxTYsp94duqpNuff/mY3FAIAKocYwPdWrbKlPgMH2pKfRHDZZXakMWaM9NFHrqcBgMREDECSLfHp0MGW+jz5pOtpKmbgQCk72443DhxwPQ0AJB5iAJJsic+nn9rTA9Wru56mYo4eF6xbZ1c2AAAVQwxAK1famfvgwbbUJxE1aWIh8PTTtjERAFB+xIDnDh2yy+uNG9syn0TWv7/FTKdO0v79rqcBgMRBDHhu1CjbK1BQYMt8Ellysv1zbNhgNxUCAMqHGPBYYaHFwJAhtsQnCBo3ln73O9ug+P77rqcBgMRADHjq4EF7eqBpU1veEyQ5OVLz5nb88e23rqcBgPhHDHhqxAhb1jN3rt2NHySnnGLHBVu22FUPAMCJEQMe+ugjW9IzdKh06aWup4mOiy6yI5DJk6Vly1xPAwDxjRjwzIEDdvk8O9uW9QRZ375Sixb2dMG+fa6nAYD4RQx4ZtgwW85TUBC844EfOuUUKT9fKiqyHQoAgGMjBjyyYoUt5Rk2zJb0+ODCC2274tSp0pIlrqcBgPhEDHhi/367XN6smS3n8Unv3lLLllLnztLeva6nAYD4Qwx4YuhQW8ZTUGDLeXySlGTHBV9/Hfz7JACgMogBD7z/vi3hGTHClvL46PzzpbFjpenTpXfecT0NAMQXYiDgvv3Wnh5o3lx69FHX07jVo4d0/fVSly5SaanraQAgfhADATdkiC3fKSiwu+t9lpQk5eVJ33zj330TAHAixECALVtmS3dGjbIlPJAaNJDGj5dmzJDefNP1NAAQH4iBgNq3z54eaNHClu/gnx5+WGrdWuraVSoudj0NALhHDATU4MG2bCc/n+OBHwqFpNmzpT177E2NAMB3xEAALVliS3aeesqW7uDH6tWzJyzmzJH+/GfX0wCAW8RAwOzda8t1Wra0ZTs4vq5dpTZtpIcesqsEAOArYiBgBg605Tr5+Xb3PI7v6HFBaanUr5/raQDAHV4uAuSdd2ypzrhxtmQHJ5eVJU2aZI9eLlrkehoAcIMYCIjSUlumc8MN0m9+43qaxNKpk3TrrVK3btLu3a6nAYDYIwYCon9/W6YzZw7HAxUVCkmzZtm2Rh7DBOAjXjYC4M03bYnO+PG2VAcVd9550pQp0h/+IL36qutpACC2iIEEV1xsd8W3bm3LdFB5//Vf0u2327/HXbtcTwMAsUMMJLicHHssbvZsu9yNyguF7ArLoUM8lgnAL8RAAvvzn+0egQkTbIkOqi4jwxY2zZ8vvfKK62kAIDaIgQS1Z48ty2nTxo4JEDn33y+1bSt17y7t3Ol6GgCIPmIgQfXrZ48TcjwQeaGQlJsrlZVJvXq5ngYAoo8YSECLFtmSnMmTbWkOIu/cc6Vnn5VeeMH+AIAgIwYSzO7dthznttukjh1dTxNs990ntWsn9ewp7djhehoAiB5iIMH07WvLcWbO5Hgg2kIhW+8sST16SOGw23kAIFqIgQTy6qu2FGfKFFuSg+g75xwLgpdflhYscD0NAEQHMZAgdu2yZTh33GHLcRA7994r/epXdlzw1VeupwGAyCMGEkTv3rYMZ8YMjgdcmDZNSk62xw05LgAQNMRAAnjlFVuCM3WqlJ7ueho/nXWWPW746qvSc8+5ngYAIosYiHM7d9pXo23b2jIcuHP33fbfoE8fqajI9TQAEDnEQJzr1cuW3+TmcjwQD6ZMkapVs/s3OC4AEBTEQBw7uvBm2jRbggP36tSx+zYWLZLmzXM9DQBEBjEQp3bssLvX77nH7mRH/LjrLnuio29fads219MAQNURA3EoHLYlN5JdFeB4IP4884xUs6a9WRTHBQASHTEQhxYssCU306fb0hvEnzPPlGbNsreRzs93PQ0AVA0xEGe++sqOB+67z5bdIH798pf2/hD9+kmbN7ueBgAqjxiII+GwPUaYnGzvmIf4N2mSlJIide3KcQGAxEUMxJHnn7elNrm5tuQG8a9WLWn2bOmtt+zPAJCIiIE4UVRkK4fvv9+W2yBx3HKLXRl49FFp0ybX0wBAxREDcSActiU21avbUhskngkT7KbCzp1tSRQAJBJiIA7Mm2dLbGbMsKU2SDypqdKcOdK779p/RwBIJMSAY9u22fKaBx+U7rzT9TSoiptusis8/ftLGza4ngYAyo8YcCgctqU1p58uTZ7sehpEwtNP282fHBcASCTEgEP5+ba0ZuZMO29G4ktJkfLypCVLbGkUACQCYsCRzZttWU2nTra8BsHxi1/YOumBA6V161xPAwAnRww4EA7bo2ipqdLEia6nQTSMHWvvNMlxAYBEQAw48K9LamrVcj0NouGMM+wYaNkyaepU19MAwIkRAzG2aZMtp+naVbr5ZtfTIJpatZL69JEGD5bWrnU9DQAcHzEQQ2Vldtn4zDNtSQ2Cb/RoKSPD7g05csT1NABwbMRADM2YYUtp8vLsfgEE3+mn23HB8uU8PgogfhEDMbJhgy2j6d5dat3a9TSIpZYtpUcekR5/XPriC9fTAMCPEQMxcPR44KyzpHHjXE8DF0aOlOrVkzp25LgAQPwhBmJg+nRbQpOXZ0tp4J+aNe244MMPuV8EQPwhBqJs3TpbPtOzpy2jgb9atJBycqQnnpDWrHE9DQD8EzEQRUePB37yE2nMGNfTIB787ndSw4ZShw7S4cOupwEAQwxE0dSptnQmL8+W0ACnnSYVFEiFhfamRgAQD4iBKFm71pbN9Oljy2eAo5o3lwYMkJ58Ulq1yvU0AEAMRMWRI7Zk5rzzbOkM8EPDhkkXXmhPF3z3netpAPiOGIiCyZNtyUx+vi2dAX6oenU7LvjkE+4nAeAeMRBhX3xhy2X69ZOuvdb1NIhnP/+5NGiQ3VT4ySeupwHgM2Iggo4cscu+9erZkhngZJ54QvrpT+3z5tAh19MA8BUxEEETJkgffWSXf087zfU0SARHjwtWreL+EgDuEAMRsmaNfZWXkyNdfbXraZBIrrjCjpZGjbJHDgEg1oiBCDh82JbINGxo579ART3+uHTJJRwXAHCDGIiAp5+2r+jmzpVq1HA9DRJRtWr2+fP559KIEa6nAeAbYqCKVq2y5TEDBkhXXul6GiSyyy6zo6annpI+/tj1NAB8QgxUwXff2WXdRo1siQxQVYMHS5deasdOBw+6ngaAL4iBKhgzxp4PLyiwu8KBqjr1VDsu+PJLAhNA7BADlfTJJ3az4ODB0s9+5noaBEnTphYC48ZJH3zgehoAPiAGKuHQITse+OlP7YwXiLQBA+yRw44dpQMHXE8DIOiIgUoYPVr67DM7HqhWzfU0CKLkZDsuWL9eGjrU9TQAgo4YqKDCQlsO8/jj9pUbEC2NG9tR1Pjx0vvvu54GQJARAxVw9HigSRPpscdcTwMf5OTYI6udOkn797ueBkBQEQMVMGKELYXheACxkpxsn2+bNklDhrieBkBQEQPl9PHHtgxm6FBbDgPEysUX27tgTpokvfee62kABBExUA4HD9oSmMsus/efB2KtXz/pqqvsuGDfPtfTAAgaYqAchg2zJTBz59pSGCDWTjnFjgu2buV+FQCRRwycxAcf2PKX4cPtxkHAlUaN7KhqyhRp6VLX0wAIEmLgBA4csKcHmjWT+vd3PQ0g9ekjXXut1LmztHev62kABAUxcAJDh9rSl4ICu6sbcC0pScrPl7Zv5/4VAJFDDBzH++/bspcRI2z5CxAvLrhAGjtWmjZNevdd19MACAJi4Bj277e7tps3t6UvQLzp2VNq1cqOC0pLXU8DINERA8cwZIgtecnPt7u4gXiTlCTl5UnffGNvagQAVUEM/MB779lyl1GjbNkLEK8aNrQnXXJzpbfecj0NgERGDPyLffvseODqq6VHHnE9DXBy3btLv/iF1KWLVFLiehoAiYoY+BePPSZt28bxABJHUpI0Z460ezf3twCoPGLgH5YutWUuTz1ly12ARFG/vjRhgjR7trR4setpACQiYkC2vKVzZ6llS6l3b9fTABX30EPSTTdJXbtKe/a4ngZAoiEGZMtbvvrK7s5O4t8IElAoZFcGSkqkRx91PQ2AROP9S9+779rylrFjbZkLkKjq1rUnYfLzpddfdz0NgETidQyUltrxwPXXSz16uJ4GqLrOnaVbbrFjg927XU8DIFF4HQMDBtjSFo4HEBShkDRrlvTttzweC6D8vH0JfOstW9by9NNSgwaupwEiJzNTmjxZmjdPeu0119MASARexkBJiS1pufFG6eGHXU8DRF6HDtIvf2mf37t2uZ4GQLzzMgZycuw8dc4cjgcQTKGQNHOmdOCA1KeP62kAxDvvXgoXL7ZHsCZOlOrVcz0NED0ZGdLUqdLzz0sLF7qeBkA88yoG9uyxpSxt2tifgaB74AHpzjvtPQy++cb1NADilVcx8Oij9jjh7Nl2GRUIulBImjFDOnxY6tXL9TQA4pU3MfD667aMZdIkKSvL9TRA7PzkJ9Kzz0oLFkgvvuh6GgDxyIsY2L3blrDcequ9RTHgm1//WvqP/7DlWjt2uJ4GQLzxIgYeecSWsMyaxfEA/BQKSdOnS+GwBUE47HoiAPEk8DHw2mu2fOWZZ6TzznM9DeDOuedaELz8svTCC66nARBPAh0Du3bZ0pXbb5cefND1NIB7v/qVdO+9dnXgq69cTwMgXgQ6Bvr0kQ4etLupOR4AzLRp0imn2OOGHBcAkAIWA3369FH9+vUVCoU0efJnev55W7qSkeF6MiB+nH229PvfS6++aguJJGn48OEKhUL67LPP3A4HSdKePXuUnZ39/R+NGjVScnKy/v73v7sezXsHDx7U2LG9JF2oe++9RO3bt3c9UkQkux4gku655x4NGDBALVpcqxEjpLvuku6/3/VUQPxp186eMOjdWzrrrEKtWLFCdevWdT0W/qFWrVpauXLl998eP368li5dqtq1a7sbCpKkQYMGKRRKkrRWL74YUnr6dtcjRUSgrgxcd911yszM1K5dtmQlN5fjAeB4nn1WOvXUg/rP/+ypadOmK8RvlriVn5+vLl26uB7De/v27VN+fr569RotyX6/pKenux0qQgJ1ZUCy5ULffiuNG2fLVgAcW5060jXXDNXChe319tsNdOiQtGaNdOiQ68lwVFKStHLlcn399S5lZNyuwkLXE/ntyy//T2ecUUdjx46U9La6dDlN48cP04033uh6tCoLXAw0aSLVrCk1a+Z6EiC+LV++XHv2fKRp08boj3+Utm+X7rvP9VT4V61aSUuX5kl6UM2bB+5/1wnoO0nrtW1bY7VqNUZDhnyiX/+6tdasWaOzzz7b9XBVErjPrl277MoAb8oCnNjSpUv1xRdfaOTIBtq+XUpK2qo6dW7WE0/M1jXX3Op6PEg6eHCfbrppgebO/VANGrieBrt311ObNklaseIBZWZK6emXqUGDBlq9erWuv/561+NVSeBiAED5DBo0SIMGDVJhoV1JO/fc+nrzzUVq0qSJ69HwDwUFLyo7+1K1a3ex61EgSTpLN954o3bufEM///lt2rRpkzZs2KCLLrrI9WBVFqgbCHv27Klbb82UtFU9erTWBRdc4HokAKi0OXPmcONgnMnNzdW4cePUtGlT3XXXXZo5c2YgbiIMhcMnXztSUlKitLQ0FRcXKzU1NRZzVdrRr3L++lfpiitcTwPEP37PAMFV3tfvQF0ZAAAAFUcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOcCEwMHDhxQ27ZtdffdjSRlq1evW7Rx40bXYwFxrU2bNrrvvkslZatLl5ZauXKl65EAOBCYGJCkbt266ZVX/iZppVq2vF3dunVzPRIQ11544QUtWPCppJVq3z5HnTt3dj0SAAcCEwM1atTQbbfdplAoJElq2vQqrV+/3vFUQHyrVavW93+9d2+xkpIC878EABWQ7HqAaJkxY4qaN79DhYWuJwHiW9++D0r6X/3+99I77yx2PQ4AB0LhcDh8sg8qKSlRWlqaiouLlZqaGou5Km37dqlFi9HauPF/JL0jqabrkYC416qVdPfdc/XGGwv0pz/9yfU4ACKkvK/fgbsy8Nxz45Wa+oqWLHlbKSmEAFAe6elSenoHDRrUXbt27VKdOnVcjwQghgIVAxMnTtT8+fO1ZMnbOvPMWq7HAeJaSUmJ9u7dq4yMDEnSwoULVadOHdWuXdvxZABiLTAxsHXrVuXk5Khhw4a64YYbJEnVq1fXBx984HgyID4VFxerXbt22r9/v5KSknT22Wdr0aJF39+EC8AfgYmBzMxMleP2BwD/kJWVpQ8//ND1GADiAM8RAQDgOWIAAADPEQMAAHiOGAAAwHPEAAAAniMGAADwHDEAAIDniAEAADxHDAAA4DliAAAAzxEDAAB4jhgAAMBzxAAAAJ4jBgAA8BwxAACA54gBAAA8RwwAAOA5YgAAAM8RAwAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADgOWIAAADPJZfng8LhsCSppKQkqsMAAIDIOfq6ffR1/HjKFQOlpaWSpKysrCqOBQAAYq20tFRpaWnH/f5Q+GS5IKmsrExFRUVKSUlRKBSK6IAAACA6wuGwSktLlZGRoaSk498ZUK4YAAAAwcUNhAAAeI4YAADAc8QAAACeIwYAAPAcMQAAgOeIAQAAPEcMAADguf8HlnSo52deRuEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# async model\n",
    "module = aegnn.asyncronous.make_model_asynchronous(module, 1.0, (10,10), attr_func)\n",
    "print('async, init:')\n",
    "module.forward(graph_init)\n",
    "print('async, add node 1:')\n",
    "module.forward(node_1)\n",
    "print('async, add node 2:')\n",
    "module.forward(node_2)\n",
    "print('async, add node 3:')\n",
    "module.forward(node_3)\n",
    "\n",
    "asy_graph = module.conv2.asy_graph\n",
    "print(f'conv2.asy_graph.num_nodes: \\n{asy_graph.num_nodes}')\n",
    "print('graph:')\n",
    "asy_graph_nx = to_networkx(asy_graph, to_undirected=True)\n",
    "nx.draw_networkx(asy_graph_nx, with_labels=True, pos=asy_graph.pos.tolist(), node_size=0, node_shape='.',  font_size=8, font_color='k',  edge_color='b', width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7723, -0.8094,  0.8872, -0.8544,  0.8056, -0.8833,  1.3316,  0.5760],\n",
      "        [-0.7723, -0.8094,  0.8872, -0.8544,  0.8056, -0.8833,  1.3316,  0.5760],\n",
      "        [-0.8729, -0.9175,  0.8380, -0.9143,  0.9301, -0.9282,  1.0294,  0.8420],\n",
      "        [-0.8137, -0.8374,  0.9283,  0.9462, -0.8054, -0.9072,  1.1500,  0.6960],\n",
      "        [-0.7723, -0.8094,  0.8872, -0.8544,  0.8056, -0.8833,  1.3316,  0.5760],\n",
      "        [-0.7812, -0.8494,  0.9154, -0.8569,  0.8282, -0.8947,  1.2578,  0.6040]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "x = tensor([[ 0.0000,  0.0000,  0.0000,  0.0, 0.0,  0.0000,  0.0000,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000, 0.0, 0.0,  0.0000,  0.0000,  0.0000],\n",
    "        [-0.0158, -0.0081, -0.0061,  -0.0263, 0.0330, -0.0169, -0.0213,  0.0428],\n",
    "        [-0.0065, -0.0021,  0.0051, 0.7905, -0.4271, -0.0090, -0.0128,  0.0193],\n",
    "        [0,0,0,0,0,0,0,0],\n",
    "        [-0.0014, -0.0030, 0.0035, -0.0011, 0.0060, -0.0043, -0.0052, 0.0045]\n",
    "        ])\n",
    "r_mean = tensor([ 0.1186,  0.0603, -0.1125,  0.3718, -0.2075,  0.3228, -0.0940, -0.0887])\n",
    "r_var = tensor([0.0233, 0.0054, 0.0151, 0.1842, 0.0778, 0.1323, 0.0052, 0.0273])\n",
    "bias = tensor([-0.0171, -0.0043, -0.0196, -0.0075,  0.0229, -0.0275, -0.0022,  0.0248])\n",
    "w = tensor([0.9722, 0.9820, 0.9908, 0.9776, 1.0522, 0.9644, 1.0242, 1.0270])\n",
    "\n",
    "x_ = ((x-r_mean)/torch.sqrt(r_var+1e-5))*w + bias\n",
    "print(x_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "device = 'cpu'\n",
    "graph = Data(\n",
    "    x = torch.tensor([1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], device=device).view(-1,1),\n",
    "    pos = torch.tensor([[2,3],[1,2],[1,1],[3,1],[3,2],[5,3],[5,2],[4,2]], device=device),\n",
    "    edge_index = torch.tensor([[0,1,1,2,2,3,3,4,4,0,4,7,7,6,6,5], [1,0,2,1,3,2,4,3,0,4,7,4,6,7,5,6]], device=device, dtype=torch.long))\n",
    "\n",
    "print(torch.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 1, 2, 3, 4, 3, 4, 7, 5, 6, 5, 6, 7, 4, 6, 7],\n",
      "        [0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 7]])\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 7],\n",
      "        [0, 1, 2, 1, 2, 3, 4, 3, 4, 7, 5, 6, 5, 6, 7, 4, 6, 7]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test radius_graph\n",
    "import torch\n",
    "from torch import tensor\n",
    "import pytorch_lightning as pl\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn.pool import radius_graph, radius\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def printg(graph):\n",
    "    import networkx as nx\n",
    "    from torch_geometric.utils import to_networkx\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    g_nx = to_networkx(graph, to_undirected=True)\n",
    "    pos = dict(zip(np.arange(graph.num_nodes),graph.pos.tolist()))\n",
    "    nx.draw_networkx(g_nx, pos=pos, with_labels=True, ax=ax, node_size=100, node_shape='o',  font_size=8, font_color='w',  edge_color='b', width=1)\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "graph = Data(\n",
    "    x = torch.tensor([1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], device=device).view(-1,1),\n",
    "    pos = torch.tensor([[2,3],[1,2],[1,1],[3,1],[3,2],[5,3],[5,2],[4,2]], device=device, dtype=torch.float)\n",
    ")\n",
    "\n",
    "edge_index_from_rg = radius_graph(graph.pos[:,:], r=1.1, max_num_neighbors=3, loop=True)\n",
    "graph.edge_index = edge_index_from_rg\n",
    "neighs = radius(graph.pos[:,:], graph.pos[:,:], r=1.1, max_num_neighbors=7)\n",
    "\n",
    "print(edge_index_from_rg)\n",
    "print(neighs)\n",
    "\n",
    "printg(graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aegnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9439450e489ce535473a2847795b2c81cbeeccb2f39d71287859ebd0392d6b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
